{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad84e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Model: models/yolov9m.pt\n",
      "Resolved model name: models/yolov9m.pt\n",
      "\n",
      " Training Started...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=models/yolov9m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=classroom_attention_yolov9m, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov9m/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov9m\\train\\classroom_attention_yolov9m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1    171648  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 128, 128, 64, 1]         \n",
      "  3                  -1  1    276960  ultralytics.nn.modules.block.AConv           [128, 240]                    \n",
      "  4                  -1  1    629520  ultralytics.nn.modules.block.RepNCSPELAN4    [240, 240, 240, 120, 1]       \n",
      "  5                  -1  1    778320  ultralytics.nn.modules.block.AConv           [240, 360]                    \n",
      "  6                  -1  1   1414080  ultralytics.nn.modules.block.RepNCSPELAN4    [360, 360, 360, 180, 1]       \n",
      "  7                  -1  1   1556160  ultralytics.nn.modules.block.AConv           [360, 480]                    \n",
      "  8                  -1  1   2511840  ultralytics.nn.modules.block.RepNCSPELAN4    [480, 480, 480, 240, 1]       \n",
      "  9                  -1  1    577440  ultralytics.nn.modules.block.SPPELAN         [480, 480, 240]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   1586880  ultralytics.nn.modules.block.RepNCSPELAN4    [840, 360, 360, 180, 1]       \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    715920  ultralytics.nn.modules.block.RepNCSPELAN4    [600, 240, 240, 120, 1]       \n",
      " 16                  -1  1    397808  ultralytics.nn.modules.block.AConv           [240, 184]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   1480320  ultralytics.nn.modules.block.RepNCSPELAN4    [544, 360, 360, 180, 1]       \n",
      " 19                  -1  1    778080  ultralytics.nn.modules.block.AConv           [360, 240]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   2627040  ultralytics.nn.modules.block.RepNCSPELAN4    [720, 480, 480, 240, 1]       \n",
      " 22        [15, 18, 21]  1   4640431  ultralytics.nn.modules.head.Detect           [5, [240, 360, 480]]          \n",
      "YOLOv9m summary: 348 layers, 20,161,935 parameters, 20,161,919 gradients, 77.6 GFLOPs\n",
      "\n",
      "Transferred 901/907 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 508.6173.6 MB/s, size: 42.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\train\\labels.cache... 1583 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1583/1583 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 495.2109.9 MB/s, size: 42.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov9m\\train\\classroom_attention_yolov9m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 149 weight(decay=0.0), 156 weight(decay=0.0005), 155 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1myolov9m\\train\\classroom_attention_yolov9m\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100       7.7G      0.649      1.751      1.318         46        640: 100%|██████████| 99/99 [00:25<00:00,  3.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.798       0.78       0.89      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      7.72G     0.5387     0.8054      1.185         44        640: 100%|██████████| 99/99 [00:24<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.659      0.807      0.894      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      7.71G     0.5848     0.7426      1.196         41        640: 100%|██████████| 99/99 [00:22<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.834      0.839      0.928      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      7.71G     0.6055     0.7184      1.216         45        640: 100%|██████████| 99/99 [00:22<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.688       0.75      0.833      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      7.72G     0.5968      0.675        1.2         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.901      0.924      0.985      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      7.66G     0.5786     0.6395      1.193         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.906      0.927      0.978      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      7.72G     0.5629     0.5885      1.186         53        640: 100%|██████████| 99/99 [00:22<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.92       0.89      0.972      0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      7.71G     0.5663     0.5771       1.18         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.964      0.978      0.994      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      7.71G     0.5593     0.5456      1.174         38        640: 100%|██████████| 99/99 [00:22<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.954      0.974      0.994        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      7.75G     0.5548      0.512      1.167         36        640: 100%|██████████| 99/99 [00:23<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.918      0.922      0.992        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      7.72G     0.5319     0.5164      1.153         41        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.996      0.995      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      7.71G     0.5284     0.4887      1.152         49        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.961      0.965      0.993      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      7.71G     0.5244     0.4772      1.143         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.971      0.986      0.995      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      7.66G     0.5213     0.4684      1.146         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.968      0.961      0.993      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      7.71G     0.5063     0.4421      1.139         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.999      0.995      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      7.72G     0.5051     0.4326       1.13         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993      0.994      0.995      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      7.71G     0.5123     0.4308      1.139         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.983      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      7.66G     0.4929     0.4191      1.132         35        640: 100%|██████████| 99/99 [00:23<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996          1      0.995      0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      7.72G     0.4977     0.4073       1.13         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      7.72G     0.4892     0.4027      1.121         36        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.989      0.999      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      7.71G     0.4863     0.3962      1.122         41        640: 100%|██████████| 99/99 [00:23<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      7.66G     0.4798      0.378      1.114         40        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.989      0.991      0.995      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      7.72G     0.4788     0.3706       1.11         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.989      0.998      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      7.71G     0.4713     0.3648      1.114         46        640: 100%|██████████| 99/99 [00:23<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.999      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      7.71G     0.4656     0.3723      1.103         40        640: 100%|██████████| 99/99 [00:23<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      7.66G     0.4699     0.3522      1.106         50        640: 100%|██████████| 99/99 [00:24<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.994      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      7.71G     0.4634      0.349      1.108         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      7.72G     0.4596     0.3468      1.107         39        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.989          1      0.995      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      7.71G     0.4635     0.3495      1.105         39        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      7.66G     0.4503     0.3423      1.096         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      7.72G     0.4575     0.3378      1.108         34        640: 100%|██████████| 99/99 [00:23<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.999      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      7.72G      0.446      0.327      1.089         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      7.71G     0.4494     0.3248      1.095         51        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      7.66G     0.4531     0.3243      1.096         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      7.71G     0.4385     0.3161      1.091         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.99      0.998      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      7.72G     0.4445     0.3085      1.086         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      7.71G     0.4327     0.3027      1.083         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.998      0.995      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      7.66G     0.4347     0.3057      1.097         49        640: 100%|██████████| 99/99 [00:23<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995      0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      7.72G     0.4332     0.3012      1.087         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      7.71G     0.4325     0.3028      1.089         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      7.71G      0.435      0.301      1.084         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      7.66G     0.4325     0.2898      1.088         46        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      7.71G     0.4315     0.3017      1.086         46        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      7.71G     0.4266     0.2937      1.078         48        640: 100%|██████████| 99/99 [00:23<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      7.71G     0.4205     0.2702      1.079         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      7.66G     0.4259     0.2789      1.083         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      7.71G     0.4247     0.2857      1.084         48        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      7.72G      0.424     0.2794      1.082         40        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      7.71G     0.4089     0.2849      1.075         49        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      7.66G     0.4123     0.2743      1.075         50        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      7.71G     0.4188     0.2788      1.079         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      7.72G     0.4123      0.278      1.077         50        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      7.71G     0.3994     0.2663      1.063         46        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.998      0.995      0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      7.76G     0.4115     0.2693      1.073         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      7.72G     0.3965     0.2647      1.068         41        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.997      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      7.72G     0.3965     0.2517      1.067         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      7.72G     0.4006     0.2545      1.068         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.995      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      7.66G      0.394     0.2504      1.064         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      7.71G     0.3972      0.259       1.07         48        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.994      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      7.72G     0.3928     0.2517      1.061         49        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      7.71G     0.3863     0.2418      1.057         39        640: 100%|██████████| 99/99 [00:23<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      7.75G      0.378     0.2387      1.056         51        640: 100%|██████████| 99/99 [00:23<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      7.72G     0.3909     0.2444      1.058         39        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      7.71G     0.3816      0.238      1.059         46        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.994      0.995      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      7.72G     0.3902     0.2358       1.06         38        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.994      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      7.66G     0.3808     0.2326      1.055         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      7.72G     0.3734     0.2311      1.054         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.995      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      7.72G     0.3833     0.2328      1.057         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      7.71G     0.3687     0.2327      1.047         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996          1      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      7.66G     0.3702     0.2215      1.048         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      7.72G     0.3739     0.2255      1.056         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.994      0.995      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      7.72G     0.3712     0.2164      1.045         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      7.71G     0.3742      0.223      1.055         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      7.66G     0.3672     0.2152      1.046         38        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996          1      0.995      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      7.72G     0.3723     0.2237      1.053         41        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.999      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      7.71G     0.3563     0.2171      1.046         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      7.71G     0.3622     0.2168      1.042         47        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      7.66G     0.3615     0.2154      1.044         44        640: 100%|██████████| 99/99 [00:23<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      7.71G     0.3535     0.2124      1.043         52        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      7.71G     0.3505     0.2076      1.038         37        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      7.71G     0.3501     0.2101      1.037         52        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      7.66G     0.3506     0.2055      1.041         51        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      7.72G     0.3511      0.205      1.038         42        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      7.72G     0.3494     0.2051      1.043         43        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      7.71G     0.3482     0.2018      1.038         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453          1          1      0.995      0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      7.66G     0.3488     0.2036       1.04         48        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      7.72G     0.3374     0.1971      1.033         48        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      7.72G     0.3351     0.1941      1.035         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      7.71G     0.3318     0.1875      1.033         35        640: 100%|██████████| 99/99 [00:23<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      7.66G     0.3389     0.1923      1.035         45        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      7.72G     0.2015     0.1544      1.031         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      7.71G     0.2023      0.111      1.027         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      7.71G     0.1995     0.1044      1.028         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      7.66G     0.1939     0.1002      1.024         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      7.71G     0.1918     0.1003      1.023         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      7.72G     0.1812    0.09578      1.028         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      7.71G     0.1863      0.096      1.022         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      7.66G     0.1808    0.09225      1.014         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      7.72G     0.1819    0.09304       1.02         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      7.71G     0.1759    0.08931      1.018         15        640: 100%|██████████| 99/99 [00:23<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.793 hours.\n",
      "Optimizer stripped from yolov9m\\train\\classroom_attention_yolov9m\\weights\\last.pt, 40.8MB\n",
      "Optimizer stripped from yolov9m\\train\\classroom_attention_yolov9m\\weights\\best.pt, 40.8MB\n",
      "\n",
      "Validating yolov9m\\train\\classroom_attention_yolov9m\\weights\\best.pt...\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLOv9m summary (fused): 151 layers, 20,016,607 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.955\n",
      "       Looking_Forward        101        101          1          1      0.995      0.965\n",
      "          Raising_Hand         96         96      0.999          1      0.995      0.961\n",
      "               Reading         73         73      0.998          1      0.995      0.964\n",
      "              Sleeping         81         81          1          1      0.995      0.951\n",
      "        Turning_Around        102        102      0.999          1      0.995      0.932\n",
      "Speed: 0.1ms preprocess, 3.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1myolov9m\\train\\classroom_attention_yolov9m\u001b[0m\n",
      "\n",
      " Training Complete!\n",
      " Training curves saved to yolov9m/training_plots\\loss_curves.png\n",
      "\n",
      " Running validation on VALIDATION split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLOv9m summary (fused): 151 layers, 20,016,607 parameters, 0 gradients, 76.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 768.997.7 MB/s, size: 40.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.955\n",
      "       Looking_Forward        101        101          1          1      0.995      0.967\n",
      "          Raising_Hand         96         96      0.999          1      0.995      0.958\n",
      "               Reading         73         73      0.998          1      0.995      0.967\n",
      "              Sleeping         81         81          1          1      0.995       0.95\n",
      "        Turning_Around        102        102      0.999          1      0.995      0.931\n",
      "Speed: 0.2ms preprocess, 6.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1myolov9m\\train\\classroom_attention_yolov9m\u001b[0m\n",
      "\n",
      " Validation Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9546\n",
      "Precision: 0.9993\n",
      "Recall: 1.0000\n",
      "Saved plot to yolov9m/evaluation_plots/validation/per_val_class_metrics.png\n",
      "\n",
      " Running validation on TEST split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 470.876.8 MB/s, size: 41.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\test\\labels.cache... 226 images, 0 backgrounds, 0 corrupt: 100%|██████████| 226/226 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        226        226      0.999          1      0.995      0.946\n",
      "       Looking_Forward         36         36          1          1      0.995      0.966\n",
      "          Raising_Hand         64         64      0.999          1      0.995      0.943\n",
      "               Reading         39         39      0.998          1      0.995      0.959\n",
      "              Sleeping         33         33          1          1      0.995      0.946\n",
      "        Turning_Around         54         54          1          1      0.995      0.917\n",
      "Speed: 0.3ms preprocess, 6.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1myolov9m\\train\\classroom_attention_yolov9m\u001b[0m\n",
      "\n",
      " Test Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9462\n",
      "Precision: 0.9993927448825517\n",
      "Recall: 1.0\n",
      "Saved plot to yolov9m/evaluation_plots/validation/per_test_class_metrics.png\n",
      " Metric plot saved to yolov9m/evaluation_plots/validation\\overall_metrics.png\n",
      " Metric plot saved to yolov9m/evaluation_plots/test\\overall_metrics.png\n",
      "\n",
      "image 1/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame109_png.rf.b654c8e2b61f8a6225af75571f5a02e2.jpg: 640x640 1 Turning_Around, 14.6ms\n",
      "image 2/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame125_png.rf.d716870a273e655de1f58987b32a366f.jpg: 640x640 1 Turning_Around, 16.0ms\n",
      "image 3/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame133_png.rf.a1d1e40193045cb2d73a508fcd2aeffb.jpg: 640x640 1 Turning_Around, 17.0ms\n",
      "image 4/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame135_png.rf.5fbfdd53694f8987c732ed7fedf2fbf0.jpg: 640x640 1 Turning_Around, 12.9ms\n",
      "image 5/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame17_png.rf.aeb1ef619d24e07b33a9b3875f2ee150.jpg: 640x640 1 Turning_Around, 16.5ms\n",
      "image 6/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame19_png.rf.4eafdeb61da26cc04e2fa644eb60365b.jpg: 640x640 1 Turning_Around, 16.0ms\n",
      "image 7/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame22_png.rf.6d8036a863a8c6c7ce3a48b582c86fad.jpg: 640x640 1 Turning_Around, 14.6ms\n",
      "image 8/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame5_png.rf.bfe5c71a6f4cde8c92061a09dcb28b49.jpg: 640x640 1 Turning_Around, 13.0ms\n",
      "image 9/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame70_png.rf.53755b2c4fe579df00539e10ef45350a.jpg: 640x640 1 Turning_Around, 16.2ms\n",
      "image 10/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame146_png.rf.b749d7f39de2d04a0b8248221af7597e.jpg: 640x640 1 Turning_Around, 13.3ms\n",
      "image 11/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame148_png.rf.961d726e5b4c9a1a08ae22c1f6dbe97d.jpg: 640x640 1 Turning_Around, 16.1ms\n",
      "image 12/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame103_png.rf.01ce420b94d0afb7ad3b63db3bb6f770.jpg: 640x640 1 Turning_Around, 14.0ms\n",
      "image 13/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame105_png.rf.af0271387ab1b7b7cf12ca957d6604c6.jpg: 640x640 1 Turning_Around, 16.1ms\n",
      "image 14/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame106_png.rf.6c30ed12b539cd4b60ae6763eeb8f314.jpg: 640x640 1 Turning_Around, 14.1ms\n",
      "image 15/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame224_png.rf.a61153714fd35c3dfa0b07860b442207.jpg: 640x640 1 Turning_Around, 21.7ms\n",
      "image 16/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame256_png.rf.4fbf0d7449f4e9b8575806f9db8eacfe.jpg: 640x640 1 Turning_Around, 11.9ms\n",
      "image 17/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame31_png.rf.6b0f54e2b6a03b201b0b92a17209a627.jpg: 640x640 1 Turning_Around, 14.9ms\n",
      "image 18/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame34_png.rf.4c930225326fddbc1d4374de3582e2b6.jpg: 640x640 1 Turning_Around, 15.3ms\n",
      "image 19/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame89_png.rf.56d3efe6023447f36212d5de407db28e.jpg: 640x640 1 Turning_Around, 11.8ms\n",
      "image 20/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame95_png.rf.665bb5e0b1cef7ae2823cbd42f05c342.jpg: 640x640 1 Turning_Around, 14.5ms\n",
      "image 21/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame13_png.rf.a711450469f8a1091fe19c32566aa238.jpg: 640x640 1 Turning_Around, 12.3ms\n",
      "image 22/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame5_png.rf.5eba38da13096817f096b5095e301f31.jpg: 640x640 1 Turning_Around, 14.3ms\n",
      "image 23/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame125_png.rf.9cd8209af1c40444c37d713a37ee6ada.jpg: 640x640 1 Turning_Around, 21.6ms\n",
      "image 24/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame129_png.rf.15dbfd4b5e038a9d7df1445fcd0158d5.jpg: 640x640 1 Turning_Around, 21.8ms\n",
      "image 25/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame220_png.rf.a182febf26d1063ab084b18b54176579.jpg: 640x640 1 Turning_Around, 12.8ms\n",
      "image 26/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame110_png.rf.8549546e1fdbca99ef9bafd306a7b9b7.jpg: 640x640 1 Turning_Around, 12.4ms\n",
      "image 27/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame99_png.rf.90ba905fbcf0a76725030075aa2a091e.jpg: 640x640 1 Turning_Around, 15.5ms\n",
      "image 28/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame105_png.rf.4939150bdf70b55c6a63b4273eb91302.jpg: 640x640 1 Turning_Around, 12.0ms\n",
      "image 29/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame106_png.rf.c3954f46abf533c03cd76aaf82cc2dd1.jpg: 640x640 1 Turning_Around, 15.4ms\n",
      "image 30/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame107_png.rf.a07b8145e09f8ca45d29c841b712a621.jpg: 640x640 1 Turning_Around, 15.5ms\n",
      "image 31/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame119_png.rf.42b83b11b10f0dfc3abb1972a215e56b.jpg: 640x640 1 Turning_Around, 22.3ms\n",
      "image 32/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame124_png.rf.31dc5b02e3c494652afcf6cb10009d17.jpg: 640x640 1 Turning_Around, 18.5ms\n",
      "image 33/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame25_png.rf.fa0159593b6cac9f28d10e7ebd205f6d.jpg: 640x640 1 Turning_Around, 14.7ms\n",
      "image 34/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame30_png.rf.7dadf09e5a45356884473213872c6142.jpg: 640x640 1 Turning_Around, 14.6ms\n",
      "image 35/226 d:\\research2\\classroom-attention\\data\\test\\images\\around09_rgb_1_frame70_png.rf.cab1fde2fe507aee7b9304c32db1c1a2.jpg: 640x640 1 Turning_Around, 12.1ms\n",
      "image 36/226 d:\\research2\\classroom-attention\\data\\test\\images\\around10_rgb_2_frame60_png.rf.275960ae1818d569f11600b90a6dfdb1.jpg: 640x640 1 Turning_Around, 21.7ms\n",
      "image 37/226 d:\\research2\\classroom-attention\\data\\test\\images\\around11_rgb_1_frame265_png.rf.610a31ab8fd2844bf0e4757e840ddf6f.jpg: 640x640 1 Turning_Around, 22.3ms\n",
      "image 38/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame191_png.rf.4b4306bb38698f6e6b83acc57083d0dc.jpg: 640x640 1 Turning_Around, 11.7ms\n",
      "image 39/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame195_png.rf.ffd60ef2677deb02437b6e8779596e95.jpg: 640x640 1 Turning_Around, 20.4ms\n",
      "image 40/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame208_png.rf.302af784d70f73bd9331c8d79a070ac1.jpg: 640x640 1 Turning_Around, 20.6ms\n",
      "image 41/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame212_png.rf.d9651e1031ad13cbe2fb362e649b8fdc.jpg: 640x640 1 Turning_Around, 19.5ms\n",
      "image 42/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame271_png.rf.5e20e287b7c0ad3fcb1888cfbd291ae5.jpg: 640x640 1 Turning_Around, 20.3ms\n",
      "image 43/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame289_png.rf.f459b40af8180d7c25f7363063ad0f04.jpg: 640x640 1 Turning_Around, 15.2ms\n",
      "image 44/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame15_png.rf.bec9cf8151bb46c295ae6391f194aa31.jpg: 640x640 1 Turning_Around, 22.6ms\n",
      "image 45/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame3_png.rf.57fb58176870090ef700d642cd94bafc.jpg: 640x640 1 Turning_Around, 20.0ms\n",
      "image 46/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame4_png.rf.0760bfb18fcbde92e29ea2aa004156a7.jpg: 640x640 1 Turning_Around, 25.4ms\n",
      "image 47/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame7_png.rf.b9bd031365d6a9f1881d25f7c8847f07.jpg: 640x640 1 Turning_Around, 19.9ms\n",
      "image 48/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame5_png.rf.975a814bcfef05a0640e15e3ec9f7c4c.jpg: 640x640 1 Turning_Around, 15.2ms\n",
      "image 49/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame7_png.rf.a2f065b02c7363a7e6140691aeb0b16f.jpg: 640x640 1 Turning_Around, 14.8ms\n",
      "image 50/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame141_png.rf.97f861930be1e79d87618ce8027ead0a.jpg: 640x640 1 Turning_Around, 14.1ms\n",
      "image 51/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame156_png.rf.dfaf9cafde4c8b4312f416173295593f.jpg: 640x640 1 Turning_Around, 20.9ms\n",
      "image 52/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame187_png.rf.1ca23609e719f17d5ddd0fc10babccec.jpg: 640x640 1 Turning_Around, 20.0ms\n",
      "image 53/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame192_png.rf.36cae9e67abda01ef56fe60ca9f4396c.jpg: 640x640 1 Turning_Around, 22.4ms\n",
      "image 54/226 d:\\research2\\classroom-attention\\data\\test\\images\\around17_rgb_1_frame130_png.rf.83f2f559afb812db78df93db294b1172.jpg: 640x640 1 Turning_Around, 15.5ms\n",
      "image 55/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame1_png.rf.99455f04937225c791a09b5d3bd15431.jpg: 640x640 1 Looking_Forward, 11.6ms\n",
      "image 56/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame4_png.rf.7d1ad65a527838d23798337da1ef499d.jpg: 640x640 1 Looking_Forward, 22.1ms\n",
      "image 57/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_1_frame1_png.rf.3d03883d2917b358b043e5bbda2c70f1.jpg: 640x640 1 Looking_Forward, 20.3ms\n",
      "image 58/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_2_frame180_png.rf.a64a769c1cd562224bf5909213d55dad.jpg: 640x640 1 Looking_Forward, 21.3ms\n",
      "image 59/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_4_frame60_png.rf.56ff5c31159577f9694dcd5641fc39f9.jpg: 640x640 1 Looking_Forward, 14.3ms\n",
      "image 60/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame148_png.rf.3f8e7e14dd62fb37f887ded1a22791c5.jpg: 640x640 1 Looking_Forward, 21.1ms\n",
      "image 61/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame153_png.rf.c6a2f8fa39a609eb9c5c31100ac8a792.jpg: 640x640 1 Looking_Forward, 22.0ms\n",
      "image 62/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame159_png.rf.02a525d0331074da812ea53ad01f1ecb.jpg: 640x640 1 Looking_Forward, 20.8ms\n",
      "image 63/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame4_png.rf.d793dadcaece19329dc8facc04ba2d3f.jpg: 640x640 1 Looking_Forward, 12.3ms\n",
      "image 64/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward04_rgb_2_frame299_png.rf.8784d9853b59961a38f76ae71e9fe178.jpg: 640x640 1 Looking_Forward, 21.5ms\n",
      "image 65/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_1_frame56_png.rf.1a9a50372478e06bd2716b0557829106.jpg: 640x640 1 Looking_Forward, 14.9ms\n",
      "image 66/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_3_frame4_png.rf.cd911f7a30af8a17dbf5c27d95905f50.jpg: 640x640 1 Looking_Forward, 22.1ms\n",
      "image 67/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame13_png.rf.39c7fe3c32b3dc57560aa09c8eb7a877.jpg: 640x640 1 Looking_Forward, 14.6ms\n",
      "image 68/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame15_png.rf.3d77a4502b13e0aba4ed9c3cb2e4e8a7.jpg: 640x640 1 Looking_Forward, 20.6ms\n",
      "image 69/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame18_png.rf.ccf95059cc8227952e07945e38c6eb62.jpg: 640x640 1 Looking_Forward, 14.5ms\n",
      "image 70/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame6_png.rf.3c0205ac3335ea8f994da934491721db.jpg: 640x640 1 Looking_Forward, 15.5ms\n",
      "image 71/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward10_rgb_4_frame130_png.rf.1af82e3fdda24c16614eb09f35d1eda7.jpg: 640x640 1 Looking_Forward, 19.8ms\n",
      "image 72/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame258_png.rf.0ef83b8f2042a34cfde49412bcf2a748.jpg: 640x640 1 Looking_Forward, 21.2ms\n",
      "image 73/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame265_png.rf.dfae9b01727c2bc2ce5130f4c3cbbbff.jpg: 640x640 1 Looking_Forward, 14.8ms\n",
      "image 74/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame276_png.rf.a5aa19bd1502964c9b0caaf4e9e814dd.jpg: 640x640 1 Looking_Forward, 14.9ms\n",
      "image 75/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame282_png.rf.6bd8b44d0fbe89059e380ee2d62869ac.jpg: 640x640 1 Looking_Forward, 12.6ms\n",
      "image 76/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame15_png.rf.4ba9de73214319ee38354c2146b13ca4.jpg: 640x640 1 Looking_Forward, 12.8ms\n",
      "image 77/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame31_png.rf.c2e1ff1e14127ba20742f613d6eadb65.jpg: 640x640 1 Looking_Forward, 15.1ms\n",
      "image 78/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward17_rgb_4_frame265_png.rf.bccb08fba9349bdf56113abd3660d51f.jpg: 640x640 1 Looking_Forward, 14.4ms\n",
      "image 79/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame274_png.rf.1021e3e1cc279a54889b946527f11a03.jpg: 640x640 1 Looking_Forward, 22.7ms\n",
      "image 80/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame275_png.rf.c38c06abc3b62b3eb4ded600dd980332.jpg: 640x640 1 Looking_Forward, 14.3ms\n",
      "image 81/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame294_png.rf.01170f58bab5570f5a6cd45f9fb0eb10.jpg: 640x640 1 Looking_Forward, 14.5ms\n",
      "image 82/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame298_png.rf.cc7d9b262ad63612836c4dc6a6d52c75.jpg: 640x640 1 Looking_Forward, 19.0ms\n",
      "image 83/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward22_rgb_4_frame4_png.rf.8cbd9b4e68c5e2bd6a70f63476431c97.jpg: 640x640 1 Looking_Forward, 15.7ms\n",
      "image 84/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward24_rgb_2_frame84_png.rf.e7df7f15b708bca038c57c6a4b1a9b52.jpg: 640x640 1 Looking_Forward, 11.5ms\n",
      "image 85/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame52_png.rf.8d87aa607ef9e6eeefa1db35104e2e8c.jpg: 640x640 1 Looking_Forward, 12.9ms\n",
      "image 86/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame63_png.rf.75bf91bde83601e65e2cf30f2954a0ec.jpg: 640x640 1 Looking_Forward, 14.5ms\n",
      "image 87/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame69_png.rf.cbd26db73ae8fe499237c032c0509b60.jpg: 640x640 1 Looking_Forward, 13.0ms\n",
      "image 88/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame75_png.rf.7b06e46d9e4e2baa38642418f6216e23.jpg: 640x640 1 Looking_Forward, 21.2ms\n",
      "image 89/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame76_png.rf.dc32bd12625090c2aae0d5874e2f4c8f.jpg: 640x640 1 Looking_Forward, 23.6ms\n",
      "image 90/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward30_rgb_1_frame94_png.rf.3c04241c702d3873763a6b4e767d9507.jpg: 640x640 1 Looking_Forward, 15.5ms\n",
      "image 91/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame100_png.rf.0308d2b0dd3c54b5cfe95ad0bb96c48b.jpg: 640x640 1 Raising_Hand, 12.8ms\n",
      "image 92/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame71_png.rf.9d06c50933c7a04230860c6401a2a5c5.jpg: 640x640 1 Raising_Hand, 13.2ms\n",
      "image 93/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame84_png.rf.289a5a0af22bf40f32f16feab04f5f50.jpg: 640x640 1 Raising_Hand, 12.8ms\n",
      "image 94/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame89_png.rf.33131c2876ba81af06ebfbf95758e932.jpg: 640x640 1 Raising_Hand, 21.3ms\n",
      "image 95/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame99_png.rf.de17495fd1af4d7530f950374b1f6933.jpg: 640x640 1 Raising_Hand, 12.1ms\n",
      "image 96/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame193_png.rf.076f557cf5122a255c2b5c2446f11da0.jpg: 640x640 1 Raising_Hand, 20.3ms\n",
      "image 97/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame196_png.rf.f18ba7130a6d28f3bb7b3608136e8837.jpg: 640x640 1 Raising_Hand, 21.3ms\n",
      "image 98/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame200_png.rf.8ccf8edc5b06faa1a410e58e75b905eb.jpg: 640x640 1 Raising_Hand, 12.1ms\n",
      "image 99/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame202_png.rf.dfbeee2974446dceb27d88fcf3aaaeba.jpg: 640x640 1 Raising_Hand, 13.1ms\n",
      "image 100/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame21_png.rf.a81a23d39c13e837f5fa77059c731fde.jpg: 640x640 1 Raising_Hand, 14.9ms\n",
      "image 101/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame29_png.rf.d3a268ae3eed65e4ec1b676a7c9f4784.jpg: 640x640 1 Raising_Hand, 14.4ms\n",
      "image 102/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame338_png.rf.61918b30a745a0bb42be8392a64dbb5b.jpg: 640x640 1 Raising_Hand, 21.7ms\n",
      "image 103/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame162_png.rf.37341cc74dd8a4d6f97121a6c0c530fe.jpg: 640x640 1 Raising_Hand, 13.0ms\n",
      "image 104/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame174_png.rf.c35f8f2b89efc9d4bcb405bc19286c25.jpg: 640x640 1 Raising_Hand, 14.8ms\n",
      "image 105/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame179_png.rf.6a9eddd503d1fc74e011e8496ea90ae4.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 106/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame187_png.rf.1d02d9dd3e8071002eef6d794fe06e60.jpg: 640x640 1 Raising_Hand, 21.7ms\n",
      "image 107/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame190_png.rf.271396f792b082080ea9849eac4d4432.jpg: 640x640 1 Raising_Hand, 20.9ms\n",
      "image 108/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame17_png.rf.ce8f1c6796509ad1454ba32803302ee1.jpg: 640x640 1 Raising_Hand, 20.5ms\n",
      "image 109/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame27_png.rf.fa2e3fdad51614c293915bad6547c947.jpg: 640x640 1 Raising_Hand, 12.1ms\n",
      "image 110/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame28_png.rf.b8c79869aa1d2c03a1f7a4bd8a540d0c.jpg: 640x640 1 Raising_Hand, 12.0ms\n",
      "image 111/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame36_png.rf.5601f633237b7a09bf3ac345d0973a83.jpg: 640x640 1 Raising_Hand, 21.8ms\n",
      "image 112/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame203_png.rf.1f192dafc6c2d5254f20d978d5686002.jpg: 640x640 1 Raising_Hand, 14.4ms\n",
      "image 113/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame204_png.rf.6e68d8179370565c072ed66f0689b0cb.jpg: 640x640 1 Raising_Hand, 14.7ms\n",
      "image 114/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame212_png.rf.d55343f0569daab52a4890575cb3810e.jpg: 640x640 1 Raising_Hand, 19.7ms\n",
      "image 115/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame213_png.rf.b03c30a0816e5964306b4024658f8939.jpg: 640x640 1 Raising_Hand, 11.6ms\n",
      "image 116/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame215_png.rf.fa7ec0ab5121ffc767f76e2debb85cfa.jpg: 640x640 1 Raising_Hand, 12.0ms\n",
      "image 117/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame218_png.rf.22c93d81dcdc72071ec156d43a8ab170.jpg: 640x640 1 Raising_Hand, 21.1ms\n",
      "image 118/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame229_png.rf.5b3f2431e34533b13c63e5133881696c.jpg: 640x640 1 Raising_Hand, 17.8ms\n",
      "image 119/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand05_rgb_1_frame222_png.rf.4a44445b3fb69cc2a10f2858958023d8.jpg: 640x640 1 Raising_Hand, 15.8ms\n",
      "image 120/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame102_png.rf.f75085213690436ec61c57c38227626c.jpg: 640x640 1 Raising_Hand, 20.0ms\n",
      "image 121/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame103_png.rf.14e4ebeabf04475336b5d33e3b6e51fa.jpg: 640x640 1 Raising_Hand, 18.0ms\n",
      "image 122/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame106_png.rf.9f71375f7cdab33ded0cdbedddc2d4fe.jpg: 640x640 1 Raising_Hand, 22.3ms\n",
      "image 123/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame109_png.rf.9b8e39c8679b5c39747b8aa4d7e579b1.jpg: 640x640 1 Raising_Hand, 11.5ms\n",
      "image 124/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame27_png.rf.2ee6d4b58aea75fd4137deb50fad6d25.jpg: 640x640 1 Raising_Hand, 21.7ms\n",
      "image 125/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame31_png.rf.2332bae29b6e7f384a88581b983cf6b7.jpg: 640x640 1 Raising_Hand, 11.7ms\n",
      "image 126/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame38_png.rf.f0e82d99c3be80985adffe9494d60694.jpg: 640x640 1 Raising_Hand, 22.0ms\n",
      "image 127/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame40_png.rf.975deb8feaad36bdc9b7e49a7ab759b8.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 128/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame97_png.rf.1e261cc55a7feae8e6e934be2c90f939.jpg: 640x640 1 Raising_Hand, 21.0ms\n",
      "image 129/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame98_png.rf.524b1cba571db62dc9f8f703f932de3a.jpg: 640x640 1 Raising_Hand, 21.7ms\n",
      "image 130/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame26_png.rf.14c9f0161735532764d417ccbd4b8282.jpg: 640x640 1 Raising_Hand, 18.5ms\n",
      "image 131/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame34_png.rf.7567ceb24555a0fb510817992280e7a0.jpg: 640x640 1 Raising_Hand, 21.3ms\n",
      "image 132/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame35_png.rf.443d7bdf0a65df556ff75e36b59d8ff6.jpg: 640x640 1 Raising_Hand, 15.5ms\n",
      "image 133/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame38_png.rf.d18325c081bec9feb31528469efca337.jpg: 640x640 1 Raising_Hand, 16.6ms\n",
      "image 134/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame39_png.rf.5be5a902aab82384981a972a72d00b39.jpg: 640x640 1 Raising_Hand, 12.9ms\n",
      "image 135/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand13_rgb_1_frame129_png.rf.818c8fab0f32e4de1cceeb8b9740d90f.jpg: 640x640 1 Raising_Hand, 13.2ms\n",
      "image 136/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame37_png.rf.5aa6658aada97f5ec95afdb99e5bfc63.jpg: 640x640 1 Raising_Hand, 14.3ms\n",
      "image 137/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame55_png.rf.4f521a852571a031f4f64b2af5ca632e.jpg: 640x640 1 Raising_Hand, 12.2ms\n",
      "image 138/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame153_png.rf.31c74561d71a24d43a210a36f3bfa64a.jpg: 640x640 1 Raising_Hand, 11.7ms\n",
      "image 139/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame156_png.rf.96c528c0a5710919b9646b28562effa5.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 140/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame160_png.rf.51a63336913d6132fcfd947a8a751cbd.jpg: 640x640 1 Raising_Hand, 11.1ms\n",
      "image 141/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame53_png.rf.4afb5029370c42d92a8aff7b1da69144.jpg: 640x640 1 Raising_Hand, 21.6ms\n",
      "image 142/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_1_frame63_png.rf.8838d4694e52be999ab5da8ef2b15fbe.jpg: 640x640 1 Raising_Hand, 19.2ms\n",
      "image 143/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame209_png.rf.a8cbc7452bdaf128d0f0c9c1bc2fb85c.jpg: 640x640 1 Raising_Hand, 13.7ms\n",
      "image 144/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame214_png.rf.2684a5d44891746107cdb5d070da0c06.jpg: 640x640 1 Raising_Hand, 11.7ms\n",
      "image 145/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame218_png.rf.eec1f6aaec32df1e1eecedfd79779a0d.jpg: 640x640 1 Raising_Hand, 16.2ms\n",
      "image 146/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame148_png.rf.d8c52a54f0e09ba983cd7030d0b2b406.jpg: 640x640 1 Raising_Hand, 14.8ms\n",
      "image 147/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame154_png.rf.09e49195999dd8d6349847e8409e79f7.jpg: 640x640 1 Raising_Hand, 14.4ms\n",
      "image 148/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame22_png.rf.8160fcd1a15da7ea746f09b16c8065fe.jpg: 640x640 1 Raising_Hand, 16.1ms\n",
      "image 149/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame27_png.rf.e60f200187b98c10cda8ff0db0f7d759.jpg: 640x640 1 Raising_Hand, 11.8ms\n",
      "image 150/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame29_png.rf.693ecf1834ba96794b7c752b6f9dfca2.jpg: 640x640 1 Raising_Hand, 20.7ms\n",
      "image 151/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand23_rgb_2_frame221_png.rf.858b87da871b6b3bb036320f876b316a.jpg: 640x640 1 Raising_Hand, 22.1ms\n",
      "image 152/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame103_png.rf.687859f4a8f45acc9bf0aa328f1372ec.jpg: 640x640 1 Raising_Hand, 13.5ms\n",
      "image 153/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame92_png.rf.ff781ed0667b74b59e6a7b0ae1bb88e5.jpg: 640x640 1 Raising_Hand, 14.6ms\n",
      "image 154/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand40_rgb_3_frame45_png.rf.9df76ddb56a43cd141ca5bc911718fda.jpg: 640x640 1 Raising_Hand, 14.9ms\n",
      "image 155/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame171_png.rf.e04b9c3232f963952ac514777f6903be.jpg: 640x640 1 Reading, 14.9ms\n",
      "image 156/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame172_png.rf.b3be0ab18f47eb716fcc63061d708bce.jpg: 640x640 1 Reading, 15.1ms\n",
      "image 157/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame180_png.rf.66d6ec325102331a64ccc33c9474d50c.jpg: 640x640 1 Reading, 14.7ms\n",
      "image 158/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame48_png.rf.f2a4d133af5d6910a8ab772a448cfdee.jpg: 640x640 1 Reading, 11.7ms\n",
      "image 159/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame3_png.rf.3ad9beef2bd405f4a4e16f88fcc7871b.jpg: 640x640 1 Reading, 14.6ms\n",
      "image 160/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame59_png.rf.e4dfbfd5219bb1393efd3408d5d21681.jpg: 640x640 1 Reading, 14.3ms\n",
      "image 161/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_1_frame16_png.rf.da7c90f7a8b2257d1d97b7e3e580064b.jpg: 640x640 1 Reading, 21.4ms\n",
      "image 162/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame137_png.rf.63107347371d18af3084d3da3c482853.jpg: 640x640 1 Reading, 12.2ms\n",
      "image 163/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame173_png.rf.14f2feabf59ecf243fe61a76d50212d1.jpg: 640x640 1 Reading, 14.6ms\n",
      "image 164/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame179_png.rf.7f00ac8180ddb000b6d8aa2dd5be5352.jpg: 640x640 1 Reading, 15.1ms\n",
      "image 165/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame192_png.rf.e1c614ecde24b1999a5c91d892c5b181.jpg: 640x640 1 Reading, 15.4ms\n",
      "image 166/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame76_png.rf.55ac3124331cff8923984a7f874f575e.jpg: 640x640 1 Reading, 21.4ms\n",
      "image 167/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame79_png.rf.b3fb2a2379b7c6a996738dfcb442711c.jpg: 640x640 1 Reading, 13.5ms\n",
      "image 168/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame83_png.rf.4d2853e5659337c00525bcacef1d1d1f.jpg: 640x640 1 Reading, 20.4ms\n",
      "image 169/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame19_png.rf.d85b5e665ceafc964b581452fabb989e.jpg: 640x640 1 Reading, 19.2ms\n",
      "image 170/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame239_png.rf.836feeacfb43e83b96e31a6c1f7095d9.jpg: 640x640 1 Reading, 21.9ms\n",
      "image 171/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame28_png.rf.4d8bb6f2dcec05fc9b7f9730d995e069.jpg: 640x640 1 Reading, 20.2ms\n",
      "image 172/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame29_png.rf.280e2dfce72dd4b34eef4bb686fd663b.jpg: 640x640 1 Reading, 18.2ms\n",
      "image 173/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame10_png.rf.8a5e3f231a8c12083cce3b6d8a8a7047.jpg: 640x640 1 Reading, 16.4ms\n",
      "image 174/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame26_png.rf.2a84662f0b45f2b9e8834ab65b81e361.jpg: 640x640 1 Reading, 14.5ms\n",
      "image 175/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame27_png.rf.96e04fb3b3cae36ae3268e7946f38338.jpg: 640x640 1 Reading, 13.8ms\n",
      "image 176/226 d:\\research2\\classroom-attention\\data\\test\\images\\read13_rgb_3_frame204_png.rf.f0b6db3ba56942d451e99df0e014c7c3.jpg: 640x640 1 Reading, 19.5ms\n",
      "image 177/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_1_frame22_png.rf.01ec55b73b0bb9d3edb6285cb15fdf50.jpg: 640x640 1 Reading, 11.2ms\n",
      "image 178/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_4_frame3_png.rf.8bc93b6d3699e91bfd3e6899fdd85a4d.jpg: 640x640 1 Reading, 11.9ms\n",
      "image 179/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame117_png.rf.1f6cbfa8432f1638e543fcfd591ebee9.jpg: 640x640 1 Reading, 12.7ms\n",
      "image 180/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame119_png.rf.3662f8ba4bb01b5cf6b5cc7495b24d9b.jpg: 640x640 1 Reading, 20.9ms\n",
      "image 181/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame131_png.rf.34540fcf480ee68f8a612f8489523e11.jpg: 640x640 1 Reading, 12.0ms\n",
      "image 182/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame133_png.rf.127bdfc99254fe09060d247a27779fff.jpg: 640x640 1 Reading, 21.5ms\n",
      "image 183/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame143_png.rf.80bced075da7b2d5e7be3b0940d913b7.jpg: 640x640 1 Reading, 14.5ms\n",
      "image 184/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame242_png.rf.45e6abe238e2e66d088ddc00ffb8d366.jpg: 640x640 1 Reading, 14.3ms\n",
      "image 185/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame120_png.rf.4ff9286dee9cf53cf26a82ba8f170dd1.jpg: 640x640 1 Reading, 23.6ms\n",
      "image 186/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame57_png.rf.5ae953d3456e283a6965299d50161fc0.jpg: 640x640 1 Reading, 15.1ms\n",
      "image 187/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame225_png.rf.6a3c71cc2b11a9e9a04eba75221e71f8.jpg: 640x640 1 Reading, 20.5ms\n",
      "image 188/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame240_png.rf.e1a259e9c07e63e97f17927276770534.jpg: 640x640 1 Reading, 21.4ms\n",
      "image 189/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame10_png.rf.baa790d16c1be891a3e4d07abdaeacfd.jpg: 640x640 1 Reading, 11.9ms\n",
      "image 190/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame23_png.rf.a670b0b861cd69a80f56f31859727d1b.jpg: 640x640 1 Reading, 16.3ms\n",
      "image 191/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame14_png.rf.90a1b46716b4787d6ac73d8bbecf9367.jpg: 640x640 1 Reading, 11.7ms\n",
      "image 192/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame16_png.rf.60dbd8cba506f1bac0348c3100ce34b6.jpg: 640x640 1 Reading, 14.9ms\n",
      "image 193/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame26_png.rf.1bfe47aa92e0283f40ef62def13d74af.jpg: 640x640 1 Reading, 12.5ms\n",
      "image 194/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame350_png.rf.d3db8b8e8d96681456460d2c7d721e52.jpg: 640x640 1 Sleeping, 15.2ms\n",
      "image 195/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame365_png.rf.7b955e726b0e21927bee79809867e935.jpg: 640x640 1 Sleeping, 12.4ms\n",
      "image 196/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame367_png.rf.8757710fd35f1cc3c071a70f34acf5d6.jpg: 640x640 1 Sleeping, 16.0ms\n",
      "image 197/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame381_png.rf.824acbd869aabe62b9c47e1b5e1b6aa8.jpg: 640x640 1 Sleeping, 14.3ms\n",
      "image 198/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame131_png.rf.0b9ff50aca0a9c4e720fd2fc019112a3.jpg: 640x640 1 Sleeping, 22.0ms\n",
      "image 199/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame132_png.rf.ae98929a07f07ca51e650b8c4330565b.jpg: 640x640 1 Sleeping, 20.6ms\n",
      "image 200/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep02_rgb_3_frame208_png.rf.8e5cea278e41d658979dc697bb4ee698.jpg: 640x640 1 Sleeping, 11.7ms\n",
      "image 201/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame10_png.rf.75992b953dacacc68a5d5a167c987f8a.jpg: 640x640 1 Sleeping, 14.6ms\n",
      "image 202/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame6_png.rf.77fce1c8dc9c8ed7d78e6cda97f344e2.jpg: 640x640 1 Sleeping, 15.4ms\n",
      "image 203/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_4_frame53_png.rf.03cea74d0449c98903ddf2f18bd0a76d.jpg: 640x640 1 Sleeping, 15.2ms\n",
      "image 204/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_1_frame7_png.rf.42c1ea116a511ab7f4cd9967858bdd63.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 205/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_3_frame2_png.rf.713fa271516429ffd48b702c4ec394f4.jpg: 640x640 1 Sleeping, 12.9ms\n",
      "image 206/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame491_png.rf.8d23c808b52aa0ba76114c8514438ad3.jpg: 640x640 1 Sleeping, 14.5ms\n",
      "image 207/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame499_png.rf.4a25a4b0a4738abb1b5f098d1d13a81f.jpg: 640x640 1 Sleeping, 21.7ms\n",
      "image 208/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame12_png.rf.00e6a56fc283463d91c5207b8e2abfea.jpg: 640x640 1 Sleeping, 11.0ms\n",
      "image 209/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame1_png.rf.fc729f7d8dab490d64600f2716c29eca.jpg: 640x640 1 Sleeping, 15.1ms\n",
      "image 210/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame5_png.rf.839270aea831b7bf95e401d3f921dca7.jpg: 640x640 1 Sleeping, 13.8ms\n",
      "image 211/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame14_png.rf.88fce954118467b425233cba75ed4d5e.jpg: 640x640 1 Sleeping, 14.9ms\n",
      "image 212/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame22_png.rf.e2680f4df744b654a8f8ad25898a96dc.jpg: 640x640 1 Sleeping, 14.5ms\n",
      "image 213/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame5_png.rf.03889e765cb346db5a9b11b4fa568011.jpg: 640x640 1 Sleeping, 14.0ms\n",
      "image 214/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_3_frame457_png.rf.38355f92db1797dcffdc4ad1ee85cc03.jpg: 640x640 1 Sleeping, 12.7ms\n",
      "image 215/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame16_png.rf.6512c41305f79fd3621ee84ac52beace.jpg: 640x640 1 Sleeping, 12.9ms\n",
      "image 216/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame5_png.rf.7211aaba76cc164190fcc0ece61f378c.jpg: 640x640 1 Sleeping, 15.1ms\n",
      "image 217/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep20_rgb_1_frame197_png.rf.56fbbc05973390d04699eef597b957b5.jpg: 640x640 1 Sleeping, 11.8ms\n",
      "image 218/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame295_png.rf.f4d3b3ca8ac0b3f1c72a884ae96c98f2.jpg: 640x640 1 Sleeping, 15.5ms\n",
      "image 219/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame306_png.rf.061aba5baac216e1d24330e7fbd51445.jpg: 640x640 1 Sleeping, 13.1ms\n",
      "image 220/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep25_rgb_1_frame3_png.rf.486a414ebb1ea6c8ac4ce613062a2447.jpg: 640x640 1 Sleeping, 12.1ms\n",
      "image 221/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame219_png.rf.a53caaf46f636872db9f6c96094dc345.jpg: 640x640 1 Sleeping, 14.2ms\n",
      "image 222/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame228_png.rf.9378688b6e21c581cd53d9c6dcdba410.jpg: 640x640 1 Sleeping, 13.1ms\n",
      "image 223/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame4_png.rf.867510b6586afde44bf821ac546d5e5e.jpg: 640x640 1 Sleeping, 14.5ms\n",
      "image 224/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame9_png.rf.5e8bff960fb897acc90df0fc49223c03.jpg: 640x640 1 Sleeping, 21.2ms\n",
      "image 225/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame13_png.rf.c313e943c01dc74cac17c3926236bc38.jpg: 640x640 1 Sleeping, 22.9ms\n",
      "image 226/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame4_png.rf.7f6a45dd314f42787b1a5d045c0e0cd1.jpg: 640x640 1 Sleeping, 14.6ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9m\\prediction_outputs\\yolov9m-pred\u001b[0m\n",
      "226 labels saved to yolov9m\\prediction_outputs\\yolov9m-pred\\labels\n",
      "\n",
      " Sample predictions saved in yolov9m\\prediction_outputs\\yolov9m-pred\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = 'models/yolov9m.pt'\n",
    "DATASET_YAML = 'data/data.yaml'\n",
    "\n",
    "TRAIN_PARAMS = {\n",
    "    'data': DATASET_YAML,\n",
    "    'epochs': 100,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'name': 'classroom_attention_yolov9m',\n",
    "    'project': 'yolov9m/train',\n",
    "    'workers': 4,\n",
    "    'optimizer': 'SGD',\n",
    "    'patience': 20,\n",
    "    'device': '0',\n",
    "    'save': True,\n",
    "    'exist_ok': True,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "def train_model(model_path, params):\n",
    "    print(f\"\\n Loading Model: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    print(\"Resolved model name:\", model.model_name)\n",
    "    \n",
    "    print(\"\\n Training Started...\\n\")\n",
    "    results = model.train(**params)\n",
    "    \n",
    "    print(\"\\n Training Complete!\")\n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model, dataset_yaml):\n",
    "    print(\"\\n Running validation on VALIDATION split...\\n\")\n",
    "    val_metrics = model.val(data=dataset_yaml, split='val')\n",
    "\n",
    "    print(\"\\n Validation Metrics:\")\n",
    "    print(f\"mAP50: {val_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {val_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {val_metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {val_metrics.box.mr:.4f}\")\n",
    "    plot_per_class_metrics(\n",
    "    val_metrics.box.p,\n",
    "    val_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov9m/evaluation_plots/validation/per_val_class_metrics.png'\n",
    ")\n",
    "    print(\"\\n Running validation on TEST split...\\n\")\n",
    "    test_metrics = model.val(data=dataset_yaml, split='test')\n",
    "\n",
    "    print(\"\\n Test Metrics:\")\n",
    "    print(f\"mAP50: {test_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {test_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {test_metrics.box.mp}\")\n",
    "    print(f\"Recall: {test_metrics.box.mr}\")\n",
    "    plot_per_class_metrics(\n",
    "    test_metrics.box.p,\n",
    "    test_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov9m/evaluation_plots/validation/per_test_class_metrics.png'\n",
    ")\n",
    "    return val_metrics, test_metrics\n",
    "\n",
    "\n",
    "def plot_metrics(metrics, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        map50 = metrics.box.map50\n",
    "        map95 = metrics.box.map\n",
    "        precision = metrics.box.mp\n",
    "        recall = metrics.box.mr\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(['mAP@50', 'mAP@50-95', 'Precision', 'Recall'],\n",
    "                [map50, map95, precision, recall],\n",
    "                color=['dodgerblue', 'teal', 'orange', 'tomato'])\n",
    "\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('Overall Detection Metrics')\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(save_dir, 'overall_metrics.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\" Metric plot saved to {plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error while plotting metrics: {e}\")\n",
    "\n",
    "\n",
    "def plot_training_loss_curves(run_dir='yolov9m/detect/exp', save_dir='yolov9m/training_plots'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results_path = os.path.join(run_dir, 'results.csv')\n",
    "    if not os.path.isfile(results_path):\n",
    "        print(f\" No results.csv found at {results_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "\n",
    "    # Plot available loss curves — check column names if needed\n",
    "    loss_keys = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plotted = False\n",
    "    for key in loss_keys:\n",
    "        if key in df.columns:\n",
    "            plt.plot(df.index, df[key], label=key)\n",
    "            plotted = True\n",
    "\n",
    "    if plotted:\n",
    "        plt.title(\"Training Loss Curves\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plot_path = os.path.join(save_dir, 'loss_curves.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" Training curves saved to {plot_path}\")\n",
    "    else:\n",
    "        print(\" No loss columns found in results.csv\")\n",
    "\n",
    "\n",
    "def plot_predictions(model, save_dir='yolov9m/prediction_outputs'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results = model.predict(\n",
    "        source=\"data/test/images\",\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        conf=0.25,\n",
    "        max_det=100,\n",
    "        project='yolov9m/prediction_outputs',\n",
    "        name='yolov9m-pred'\n",
    "    )\n",
    "    print(f\"\\n Sample predictions saved in {results[0].save_dir}\")\n",
    "\n",
    "def plot_per_class_metrics(precision, recall, class_names=None, save_path=None):\n",
    "    num_classes = len(precision)\n",
    "    indices = np.arange(num_classes)\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    width = 0.35  # Width of bars\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(indices - width/2, precision, width, label='Precision', color='skyblue')\n",
    "    plt.bar(indices + width/2, recall, width, label='Recall', color='salmon')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Per-Class Precision and Recall')\n",
    "    plt.xticks(indices, class_names, rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "model, train_results = train_model(MODEL_NAME, TRAIN_PARAMS)\n",
    "\n",
    "plot_training_loss_curves(run_dir='yolov9m/train/classroom_attention_yolov9m')\n",
    "\n",
    "val_metrics, test_metrics = evaluate_model(model, DATASET_YAML)\n",
    "plot_metrics(val_metrics, save_dir='yolov9m/evaluation_plots/validation')\n",
    "plot_metrics(test_metrics, save_dir='yolov9m/evaluation_plots/test')\n",
    "plot_predictions(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
