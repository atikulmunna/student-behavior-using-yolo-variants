{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e11b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Model: models/yolo12m.pt\n",
      "Resolved model name: models/yolo12m.pt\n",
      "\n",
      " Training Started...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=models/yolo12m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=classroom_attention_yolov12m, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov12m/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov12m\\train\\classroom_attention_yolov12m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 4]        \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1   1248768  ultralytics.nn.modules.block.A2C2f           [1024, 512, 1, False, -1]     \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1    378624  ultralytics.nn.modules.block.A2C2f           [1024, 256, 1, False, -1]     \n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1   1183232  ultralytics.nn.modules.block.A2C2f           [768, 512, 1, False, -1]      \n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 21        [14, 17, 20]  1   1414879  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "YOLOv12m summary: 292 layers, 20,141,343 parameters, 20,141,327 gradients, 67.8 GFLOPs\n",
      "\n",
      "Transferred 745/751 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 512.8155.9 MB/s, size: 42.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\train\\labels.cache... 1583 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1583/1583 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 499.0124.3 MB/s, size: 42.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov12m\\train\\classroom_attention_yolov12m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 123 weight(decay=0.0), 130 weight(decay=0.0005), 129 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1myolov12m\\train\\classroom_attention_yolov12m\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      11.2G      0.608      1.633      1.279         46        640: 100%|██████████| 99/99 [00:40<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.91       0.91       0.98      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      11.1G     0.5717     0.8127      1.211         44        640: 100%|██████████| 99/99 [00:32<00:00,  3.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.786      0.841      0.913      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      11.1G     0.6316     0.8192      1.239         41        640: 100%|██████████| 99/99 [00:31<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.694      0.761      0.837      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      11.1G     0.6252     0.8455      1.238         45        640: 100%|██████████| 99/99 [00:30<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.689      0.753      0.783      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      11.1G     0.6156     0.7831       1.22         43        640: 100%|██████████| 99/99 [00:42<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.351      0.417      0.332      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      11.4G     0.5871     0.7605      1.207         43        640: 100%|██████████| 99/99 [00:27<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.694      0.804      0.906      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      11.1G     0.5855     0.7137      1.205         53        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.909      0.867      0.948      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      11.1G     0.5893     0.6683      1.199         42        640: 100%|██████████| 99/99 [00:27<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.975      0.992      0.995      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      11.1G     0.5745     0.6299      1.193         38        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.985      0.995      0.995      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      11.1G     0.5719     0.6017      1.186         36        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.967      0.978      0.994      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      11.1G     0.5581     0.5821      1.175         41        640: 100%|██████████| 99/99 [00:27<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.931      0.959      0.987      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      11.1G     0.5523     0.5504      1.173         49        640: 100%|██████████| 99/99 [00:27<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.968      0.985      0.992      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      11.1G     0.5529     0.5245      1.166         42        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.952      0.984      0.993      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      11.4G     0.5465     0.5081      1.166         45        640: 100%|██████████| 99/99 [00:32<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.936      0.965       0.99      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      11.1G     0.5377     0.5152      1.162         43        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.984       0.99      0.995      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      11.1G     0.5324     0.4886      1.152         43        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.987      0.964      0.993      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      11.1G     0.5309     0.4828      1.152         44        640: 100%|██████████| 99/99 [00:27<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.983      0.986      0.995      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      11.4G     0.5214     0.4563      1.157         35        640: 100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.986      0.985      0.994      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      11.1G     0.5189     0.4322      1.148         45        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.991      0.995      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      11.1G      0.513     0.4213       1.14         36        640: 100%|██████████| 99/99 [00:27<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      11.1G     0.5098     0.4168      1.144         41        640: 100%|██████████| 99/99 [00:27<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.994      0.995      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      11.4G     0.4953     0.4208       1.13         40        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      11.1G     0.5019      0.406       1.13         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.998      0.995      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      11.1G     0.5033     0.4024      1.136         46        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      11.1G     0.4919     0.4056      1.124         40        640: 100%|██████████| 99/99 [00:28<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993      0.995      0.995      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      11.1G      0.493     0.3829      1.124         50        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      11.1G     0.4871     0.3848      1.123         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.997      0.995       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      11.1G     0.4844     0.3741      1.123         39        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      11.1G     0.4867      0.377      1.119         39        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.997      0.995      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      11.4G     0.4719     0.3622      1.111         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.995      0.995      0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      11.1G     0.4817     0.3558      1.125         34        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.999      0.995       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      11.1G     0.4722     0.3586      1.104         44        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.994      0.995      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      11.1G     0.4773     0.3585      1.115         51        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.994      0.995       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      11.1G     0.4773       0.35      1.116         45        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993      0.994      0.994       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      11.1G     0.4615     0.3365      1.107         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.979       0.99      0.995      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      11.1G     0.4636      0.333      1.099         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.997      0.995      0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      11.1G     0.4553     0.3348      1.103         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.999      0.995      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      11.1G     0.4636     0.3282      1.117         49        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      11.1G     0.4572      0.321      1.106         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      11.1G     0.4519     0.3237      1.102         43        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.996      0.995      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      11.1G     0.4564      0.315        1.1         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      11.4G     0.4567     0.2999      1.107         46        640: 100%|██████████| 99/99 [00:28<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.992      0.996      0.995      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      11.1G     0.4572     0.3141      1.104         46        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.995      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      11.1G     0.4517     0.3135      1.098         48        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      11.1G      0.442     0.3035      1.094         43        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.998      0.995      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      11.1G     0.4493     0.3059        1.1         42        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.997      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      11.1G     0.4471     0.3144      1.098         48        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.994      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      11.1G     0.4481     0.2976        1.1         40        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      11.1G     0.4316      0.301      1.094         49        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      11.1G     0.4381     0.2917      1.093         50        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      11.1G     0.4451     0.2918      1.099         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.996      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      11.1G     0.4441     0.2975      1.096         50        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.997      0.995      0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      11.1G     0.4253     0.2871      1.082         46        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.934      0.992      0.992      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      11.1G      0.437     0.2813       1.09         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.994      0.996      0.995      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      11.1G     0.4176     0.2762      1.082         41        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.997      0.995      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      11.1G     0.4182     0.2623      1.082         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      11.1G     0.4237     0.2731      1.085         42        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.994      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      11.1G      0.418     0.2631       1.08         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.942      0.996      0.992      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      11.1G     0.4214     0.2763      1.088         48        640: 100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.996      0.995      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      11.1G     0.4229     0.2697      1.083         49        640: 100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      11.1G      0.415     0.2562      1.078         39        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      11.1G     0.4044     0.2535      1.073         51        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      11.1G     0.4187     0.2531      1.076         39        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.994      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      11.1G     0.4065     0.2516      1.077         46        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.994      0.995      0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      11.1G      0.413     0.2562      1.076         38        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.995      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      11.1G     0.4063     0.2507      1.071         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.995      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      11.1G     0.4048     0.2505      1.073         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      11.1G     0.4131     0.2521      1.075         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.999      0.995      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      11.1G     0.4045     0.2493      1.068         43        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.995      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      11.4G     0.4016     0.2456      1.068         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      11.1G     0.3996     0.2425       1.07         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      11.1G     0.3943     0.2342      1.059         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      11.1G      0.398     0.2363      1.071         42        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      11.1G     0.3954     0.2281      1.065         38        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.996      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      11.1G     0.3967     0.2392      1.071         41        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.996      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      11.1G     0.3871     0.2332      1.064         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      11.1G     0.3835     0.2244      1.056         47        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      11.1G     0.3846     0.2258      1.061         44        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453          1          1      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      11.1G     0.3761     0.2232       1.06         52        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      11.1G     0.3781     0.2267      1.055         37        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      11.1G     0.3713     0.2201      1.054         52        640: 100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453          1          1      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      11.1G     0.3805     0.2185      1.059         51        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453          1          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      11.1G     0.3789     0.2133      1.056         42        640: 100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.984      0.999      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      11.1G     0.3771     0.2148      1.061         43        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      11.1G      0.373     0.2146      1.054         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      11.1G     0.3755     0.2152      1.058         48        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      11.1G     0.3641     0.2108       1.05         48        640: 100%|██████████| 99/99 [00:27<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.997      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      11.1G     0.3657     0.2062      1.053         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.997      0.995      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      11.1G     0.3613     0.2041      1.053         35        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.988      0.996      0.995      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      11.1G     0.3688     0.2022       1.05         45        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      11.1G     0.2225      0.188      1.058         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.996      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      11.1G     0.2193     0.1224      1.046         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.997      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      11.1G     0.2148     0.1139      1.042         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      11.4G     0.2103     0.1114      1.042         15        640: 100%|██████████| 99/99 [00:35<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      11.1G     0.2093     0.1092      1.044         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      11.1G     0.1987     0.1061      1.048         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      11.1G     0.2033     0.1013      1.038         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      11.1G     0.1967    0.09965      1.032         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      11.1G     0.1998     0.1037      1.038         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      11.1G     0.1889    0.09708      1.032         15        640: 100%|██████████| 99/99 [00:28<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.916 hours.\n",
      "Optimizer stripped from yolov12m\\train\\classroom_attention_yolov12m\\weights\\last.pt, 40.8MB\n",
      "Optimizer stripped from yolov12m\\train\\classroom_attention_yolov12m\\weights\\best.pt, 40.8MB\n",
      "\n",
      "Validating yolov12m\\train\\classroom_attention_yolov12m\\weights\\best.pt...\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLOv12m summary (fused): 169 layers, 20,108,767 parameters, 0 gradients, 67.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.946\n",
      "       Looking_Forward        101        101          1          1      0.995       0.96\n",
      "          Raising_Hand         96         96      0.995          1      0.995      0.945\n",
      "               Reading         73         73          1          1      0.995      0.953\n",
      "              Sleeping         81         81      0.995          1      0.995      0.936\n",
      "        Turning_Around        102        102      0.996          1      0.995      0.936\n",
      "Speed: 0.1ms preprocess, 4.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1myolov12m\\train\\classroom_attention_yolov12m\u001b[0m\n",
      "\n",
      " Training Complete!\n",
      " Training curves saved to yolov12m/training_plots\\loss_curves.png\n",
      "\n",
      " Running validation on VALIDATION split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLOv12m summary (fused): 169 layers, 20,108,767 parameters, 0 gradients, 67.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 613.1156.4 MB/s, size: 40.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:04<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995      0.946\n",
      "       Looking_Forward        101        101          1          1      0.995       0.96\n",
      "          Raising_Hand         96         96      0.995          1      0.995      0.946\n",
      "               Reading         73         73          1          1      0.995      0.957\n",
      "              Sleeping         81         81      0.995          1      0.995      0.936\n",
      "        Turning_Around        102        102      0.986          1      0.995      0.933\n",
      "Speed: 0.2ms preprocess, 7.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov12m\\train\\classroom_attention_yolov12m\u001b[0m\n",
      "\n",
      " Validation Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9462\n",
      "Precision: 0.9953\n",
      "Recall: 1.0000\n",
      "Saved plot to yolov12m/evaluation_plots/validation/per_val_class_metrics.png\n",
      "\n",
      " Running validation on TEST split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 544.198.4 MB/s, size: 41.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\test\\labels.cache... 226 images, 0 backgrounds, 0 corrupt: 100%|██████████| 226/226 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        226        226      0.999          1      0.995      0.942\n",
      "       Looking_Forward         36         36          1          1      0.995      0.964\n",
      "          Raising_Hand         64         64          1          1      0.995       0.95\n",
      "               Reading         39         39          1          1      0.995      0.954\n",
      "              Sleeping         33         33      0.997          1      0.995      0.934\n",
      "        Turning_Around         54         54          1          1      0.995      0.907\n",
      "Speed: 0.3ms preprocess, 7.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolov12m\\train\\classroom_attention_yolov12m\u001b[0m\n",
      "\n",
      " Test Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9419\n",
      "Precision: 0.999401959341377\n",
      "Recall: 1.0\n",
      "Saved plot to yolov12m/evaluation_plots/validation/per_test_class_metrics.png\n",
      " Metric plot saved to yolov12m/evaluation_plots/validation\\overall_metrics.png\n",
      " Metric plot saved to yolov12m/evaluation_plots/test\\overall_metrics.png\n",
      "\n",
      "image 1/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame109_png.rf.b654c8e2b61f8a6225af75571f5a02e2.jpg: 640x640 1 Turning_Around, 12.0ms\n",
      "image 2/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame125_png.rf.d716870a273e655de1f58987b32a366f.jpg: 640x640 1 Turning_Around, 12.1ms\n",
      "image 3/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame133_png.rf.a1d1e40193045cb2d73a508fcd2aeffb.jpg: 640x640 1 Turning_Around, 11.9ms\n",
      "image 4/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame135_png.rf.5fbfdd53694f8987c732ed7fedf2fbf0.jpg: 640x640 1 Turning_Around, 13.6ms\n",
      "image 5/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame17_png.rf.aeb1ef619d24e07b33a9b3875f2ee150.jpg: 640x640 1 Turning_Around, 14.1ms\n",
      "image 6/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame19_png.rf.4eafdeb61da26cc04e2fa644eb60365b.jpg: 640x640 1 Turning_Around, 11.3ms\n",
      "image 7/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame22_png.rf.6d8036a863a8c6c7ce3a48b582c86fad.jpg: 640x640 1 Turning_Around, 11.9ms\n",
      "image 8/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame5_png.rf.bfe5c71a6f4cde8c92061a09dcb28b49.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 9/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame70_png.rf.53755b2c4fe579df00539e10ef45350a.jpg: 640x640 1 Turning_Around, 12.7ms\n",
      "image 10/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame146_png.rf.b749d7f39de2d04a0b8248221af7597e.jpg: 640x640 1 Turning_Around, 14.7ms\n",
      "image 11/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame148_png.rf.961d726e5b4c9a1a08ae22c1f6dbe97d.jpg: 640x640 1 Turning_Around, 10.5ms\n",
      "image 12/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame103_png.rf.01ce420b94d0afb7ad3b63db3bb6f770.jpg: 640x640 1 Turning_Around, 13.3ms\n",
      "image 13/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame105_png.rf.af0271387ab1b7b7cf12ca957d6604c6.jpg: 640x640 1 Turning_Around, 10.2ms\n",
      "image 14/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame106_png.rf.6c30ed12b539cd4b60ae6763eeb8f314.jpg: 640x640 1 Turning_Around, 11.7ms\n",
      "image 15/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame224_png.rf.a61153714fd35c3dfa0b07860b442207.jpg: 640x640 1 Turning_Around, 11.4ms\n",
      "image 16/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame256_png.rf.4fbf0d7449f4e9b8575806f9db8eacfe.jpg: 640x640 1 Turning_Around, 11.3ms\n",
      "image 17/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame31_png.rf.6b0f54e2b6a03b201b0b92a17209a627.jpg: 640x640 1 Turning_Around, 10.2ms\n",
      "image 18/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame34_png.rf.4c930225326fddbc1d4374de3582e2b6.jpg: 640x640 1 Turning_Around, 10.4ms\n",
      "image 19/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame89_png.rf.56d3efe6023447f36212d5de407db28e.jpg: 640x640 1 Turning_Around, 11.6ms\n",
      "image 20/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame95_png.rf.665bb5e0b1cef7ae2823cbd42f05c342.jpg: 640x640 1 Turning_Around, 11.8ms\n",
      "image 21/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame13_png.rf.a711450469f8a1091fe19c32566aa238.jpg: 640x640 1 Turning_Around, 11.0ms\n",
      "image 22/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame5_png.rf.5eba38da13096817f096b5095e301f31.jpg: 640x640 1 Turning_Around, 9.8ms\n",
      "image 23/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame125_png.rf.9cd8209af1c40444c37d713a37ee6ada.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 24/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame129_png.rf.15dbfd4b5e038a9d7df1445fcd0158d5.jpg: 640x640 1 Turning_Around, 11.0ms\n",
      "image 25/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame220_png.rf.a182febf26d1063ab084b18b54176579.jpg: 640x640 1 Turning_Around, 11.5ms\n",
      "image 26/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame110_png.rf.8549546e1fdbca99ef9bafd306a7b9b7.jpg: 640x640 1 Turning_Around, 10.7ms\n",
      "image 27/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame99_png.rf.90ba905fbcf0a76725030075aa2a091e.jpg: 640x640 1 Turning_Around, 11.1ms\n",
      "image 28/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame105_png.rf.4939150bdf70b55c6a63b4273eb91302.jpg: 640x640 1 Turning_Around, 9.7ms\n",
      "image 29/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame106_png.rf.c3954f46abf533c03cd76aaf82cc2dd1.jpg: 640x640 1 Turning_Around, 10.7ms\n",
      "image 30/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame107_png.rf.a07b8145e09f8ca45d29c841b712a621.jpg: 640x640 1 Turning_Around, 11.0ms\n",
      "image 31/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame119_png.rf.42b83b11b10f0dfc3abb1972a215e56b.jpg: 640x640 1 Turning_Around, 11.2ms\n",
      "image 32/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame124_png.rf.31dc5b02e3c494652afcf6cb10009d17.jpg: 640x640 1 Turning_Around, 11.8ms\n",
      "image 33/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame25_png.rf.fa0159593b6cac9f28d10e7ebd205f6d.jpg: 640x640 1 Turning_Around, 11.7ms\n",
      "image 34/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame30_png.rf.7dadf09e5a45356884473213872c6142.jpg: 640x640 1 Turning_Around, 10.4ms\n",
      "image 35/226 d:\\research2\\classroom-attention\\data\\test\\images\\around09_rgb_1_frame70_png.rf.cab1fde2fe507aee7b9304c32db1c1a2.jpg: 640x640 1 Turning_Around, 11.5ms\n",
      "image 36/226 d:\\research2\\classroom-attention\\data\\test\\images\\around10_rgb_2_frame60_png.rf.275960ae1818d569f11600b90a6dfdb1.jpg: 640x640 1 Turning_Around, 10.0ms\n",
      "image 37/226 d:\\research2\\classroom-attention\\data\\test\\images\\around11_rgb_1_frame265_png.rf.610a31ab8fd2844bf0e4757e840ddf6f.jpg: 640x640 1 Turning_Around, 12.1ms\n",
      "image 38/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame191_png.rf.4b4306bb38698f6e6b83acc57083d0dc.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 39/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame195_png.rf.ffd60ef2677deb02437b6e8779596e95.jpg: 640x640 1 Turning_Around, 10.4ms\n",
      "image 40/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame208_png.rf.302af784d70f73bd9331c8d79a070ac1.jpg: 640x640 1 Turning_Around, 10.5ms\n",
      "image 41/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame212_png.rf.d9651e1031ad13cbe2fb362e649b8fdc.jpg: 640x640 1 Turning_Around, 10.6ms\n",
      "image 42/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame271_png.rf.5e20e287b7c0ad3fcb1888cfbd291ae5.jpg: 640x640 1 Turning_Around, 12.0ms\n",
      "image 43/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame289_png.rf.f459b40af8180d7c25f7363063ad0f04.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 44/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame15_png.rf.bec9cf8151bb46c295ae6391f194aa31.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 45/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame3_png.rf.57fb58176870090ef700d642cd94bafc.jpg: 640x640 1 Turning_Around, 11.5ms\n",
      "image 46/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame4_png.rf.0760bfb18fcbde92e29ea2aa004156a7.jpg: 640x640 1 Turning_Around, 11.8ms\n",
      "image 47/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame7_png.rf.b9bd031365d6a9f1881d25f7c8847f07.jpg: 640x640 1 Turning_Around, 11.0ms\n",
      "image 48/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame5_png.rf.975a814bcfef05a0640e15e3ec9f7c4c.jpg: 640x640 1 Turning_Around, 12.6ms\n",
      "image 49/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame7_png.rf.a2f065b02c7363a7e6140691aeb0b16f.jpg: 640x640 1 Turning_Around, 11.3ms\n",
      "image 50/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame141_png.rf.97f861930be1e79d87618ce8027ead0a.jpg: 640x640 1 Turning_Around, 11.4ms\n",
      "image 51/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame156_png.rf.dfaf9cafde4c8b4312f416173295593f.jpg: 640x640 1 Turning_Around, 11.3ms\n",
      "image 52/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame187_png.rf.1ca23609e719f17d5ddd0fc10babccec.jpg: 640x640 1 Turning_Around, 10.2ms\n",
      "image 53/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame192_png.rf.36cae9e67abda01ef56fe60ca9f4396c.jpg: 640x640 1 Turning_Around, 11.6ms\n",
      "image 54/226 d:\\research2\\classroom-attention\\data\\test\\images\\around17_rgb_1_frame130_png.rf.83f2f559afb812db78df93db294b1172.jpg: 640x640 1 Turning_Around, 10.3ms\n",
      "image 55/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame1_png.rf.99455f04937225c791a09b5d3bd15431.jpg: 640x640 1 Looking_Forward, 10.5ms\n",
      "image 56/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame4_png.rf.7d1ad65a527838d23798337da1ef499d.jpg: 640x640 1 Looking_Forward, 12.1ms\n",
      "image 57/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_1_frame1_png.rf.3d03883d2917b358b043e5bbda2c70f1.jpg: 640x640 1 Looking_Forward, 10.5ms\n",
      "image 58/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_2_frame180_png.rf.a64a769c1cd562224bf5909213d55dad.jpg: 640x640 1 Looking_Forward, 10.5ms\n",
      "image 59/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_4_frame60_png.rf.56ff5c31159577f9694dcd5641fc39f9.jpg: 640x640 1 Looking_Forward, 11.9ms\n",
      "image 60/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame148_png.rf.3f8e7e14dd62fb37f887ded1a22791c5.jpg: 640x640 1 Looking_Forward, 9.9ms\n",
      "image 61/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame153_png.rf.c6a2f8fa39a609eb9c5c31100ac8a792.jpg: 640x640 1 Looking_Forward, 10.1ms\n",
      "image 62/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame159_png.rf.02a525d0331074da812ea53ad01f1ecb.jpg: 640x640 1 Looking_Forward, 11.0ms\n",
      "image 63/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame4_png.rf.d793dadcaece19329dc8facc04ba2d3f.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 64/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward04_rgb_2_frame299_png.rf.8784d9853b59961a38f76ae71e9fe178.jpg: 640x640 1 Looking_Forward, 11.5ms\n",
      "image 65/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_1_frame56_png.rf.1a9a50372478e06bd2716b0557829106.jpg: 640x640 1 Looking_Forward, 11.0ms\n",
      "image 66/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_3_frame4_png.rf.cd911f7a30af8a17dbf5c27d95905f50.jpg: 640x640 1 Looking_Forward, 11.2ms\n",
      "image 67/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame13_png.rf.39c7fe3c32b3dc57560aa09c8eb7a877.jpg: 640x640 1 Looking_Forward, 12.1ms\n",
      "image 68/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame15_png.rf.3d77a4502b13e0aba4ed9c3cb2e4e8a7.jpg: 640x640 1 Looking_Forward, 11.8ms\n",
      "image 69/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame18_png.rf.ccf95059cc8227952e07945e38c6eb62.jpg: 640x640 1 Looking_Forward, 11.5ms\n",
      "image 70/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame6_png.rf.3c0205ac3335ea8f994da934491721db.jpg: 640x640 1 Looking_Forward, 10.5ms\n",
      "image 71/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward10_rgb_4_frame130_png.rf.1af82e3fdda24c16614eb09f35d1eda7.jpg: 640x640 1 Looking_Forward, 10.9ms\n",
      "image 72/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame258_png.rf.0ef83b8f2042a34cfde49412bcf2a748.jpg: 640x640 1 Looking_Forward, 10.9ms\n",
      "image 73/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame265_png.rf.dfae9b01727c2bc2ce5130f4c3cbbbff.jpg: 640x640 1 Looking_Forward, 10.0ms\n",
      "image 74/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame276_png.rf.a5aa19bd1502964c9b0caaf4e9e814dd.jpg: 640x640 1 Looking_Forward, 12.0ms\n",
      "image 75/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame282_png.rf.6bd8b44d0fbe89059e380ee2d62869ac.jpg: 640x640 1 Looking_Forward, 11.7ms\n",
      "image 76/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame15_png.rf.4ba9de73214319ee38354c2146b13ca4.jpg: 640x640 1 Looking_Forward, 11.1ms\n",
      "image 77/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame31_png.rf.c2e1ff1e14127ba20742f613d6eadb65.jpg: 640x640 1 Looking_Forward, 11.3ms\n",
      "image 78/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward17_rgb_4_frame265_png.rf.bccb08fba9349bdf56113abd3660d51f.jpg: 640x640 1 Looking_Forward, 10.7ms\n",
      "image 79/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame274_png.rf.1021e3e1cc279a54889b946527f11a03.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 80/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame275_png.rf.c38c06abc3b62b3eb4ded600dd980332.jpg: 640x640 1 Looking_Forward, 12.1ms\n",
      "image 81/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame294_png.rf.01170f58bab5570f5a6cd45f9fb0eb10.jpg: 640x640 1 Looking_Forward, 9.8ms\n",
      "image 82/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame298_png.rf.cc7d9b262ad63612836c4dc6a6d52c75.jpg: 640x640 1 Looking_Forward, 10.0ms\n",
      "image 83/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward22_rgb_4_frame4_png.rf.8cbd9b4e68c5e2bd6a70f63476431c97.jpg: 640x640 1 Looking_Forward, 11.1ms\n",
      "image 84/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward24_rgb_2_frame84_png.rf.e7df7f15b708bca038c57c6a4b1a9b52.jpg: 640x640 1 Looking_Forward, 11.3ms\n",
      "image 85/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame52_png.rf.8d87aa607ef9e6eeefa1db35104e2e8c.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 86/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame63_png.rf.75bf91bde83601e65e2cf30f2954a0ec.jpg: 640x640 1 Looking_Forward, 11.8ms\n",
      "image 87/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame69_png.rf.cbd26db73ae8fe499237c032c0509b60.jpg: 640x640 1 Looking_Forward, 11.4ms\n",
      "image 88/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame75_png.rf.7b06e46d9e4e2baa38642418f6216e23.jpg: 640x640 1 Looking_Forward, 11.8ms\n",
      "image 89/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame76_png.rf.dc32bd12625090c2aae0d5874e2f4c8f.jpg: 640x640 1 Looking_Forward, 10.2ms\n",
      "image 90/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward30_rgb_1_frame94_png.rf.3c04241c702d3873763a6b4e767d9507.jpg: 640x640 1 Looking_Forward, 9.9ms\n",
      "image 91/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame100_png.rf.0308d2b0dd3c54b5cfe95ad0bb96c48b.jpg: 640x640 1 Raising_Hand, 12.9ms\n",
      "image 92/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame71_png.rf.9d06c50933c7a04230860c6401a2a5c5.jpg: 640x640 1 Raising_Hand, 12.0ms\n",
      "image 93/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame84_png.rf.289a5a0af22bf40f32f16feab04f5f50.jpg: 640x640 1 Raising_Hand, 10.1ms\n",
      "image 94/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame89_png.rf.33131c2876ba81af06ebfbf95758e932.jpg: 640x640 1 Raising_Hand, 10.8ms\n",
      "image 95/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame99_png.rf.de17495fd1af4d7530f950374b1f6933.jpg: 640x640 1 Raising_Hand, 11.8ms\n",
      "image 96/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame193_png.rf.076f557cf5122a255c2b5c2446f11da0.jpg: 640x640 1 Raising_Hand, 11.2ms\n",
      "image 97/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame196_png.rf.f18ba7130a6d28f3bb7b3608136e8837.jpg: 640x640 1 Raising_Hand, 11.1ms\n",
      "image 98/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame200_png.rf.8ccf8edc5b06faa1a410e58e75b905eb.jpg: 640x640 1 Raising_Hand, 10.3ms\n",
      "image 99/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame202_png.rf.dfbeee2974446dceb27d88fcf3aaaeba.jpg: 640x640 1 Raising_Hand, 11.1ms\n",
      "image 100/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame21_png.rf.a81a23d39c13e837f5fa77059c731fde.jpg: 640x640 1 Raising_Hand, 10.6ms\n",
      "image 101/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame29_png.rf.d3a268ae3eed65e4ec1b676a7c9f4784.jpg: 640x640 1 Raising_Hand, 10.1ms\n",
      "image 102/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame338_png.rf.61918b30a745a0bb42be8392a64dbb5b.jpg: 640x640 1 Raising_Hand, 10.4ms\n",
      "image 103/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame162_png.rf.37341cc74dd8a4d6f97121a6c0c530fe.jpg: 640x640 1 Raising_Hand, 11.5ms\n",
      "image 104/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame174_png.rf.c35f8f2b89efc9d4bcb405bc19286c25.jpg: 640x640 1 Raising_Hand, 10.6ms\n",
      "image 105/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame179_png.rf.6a9eddd503d1fc74e011e8496ea90ae4.jpg: 640x640 1 Raising_Hand, 11.0ms\n",
      "image 106/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame187_png.rf.1d02d9dd3e8071002eef6d794fe06e60.jpg: 640x640 1 Raising_Hand, 10.2ms\n",
      "image 107/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame190_png.rf.271396f792b082080ea9849eac4d4432.jpg: 640x640 1 Raising_Hand, 11.2ms\n",
      "image 108/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame17_png.rf.ce8f1c6796509ad1454ba32803302ee1.jpg: 640x640 1 Raising_Hand, 10.0ms\n",
      "image 109/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame27_png.rf.fa2e3fdad51614c293915bad6547c947.jpg: 640x640 1 Raising_Hand, 12.9ms\n",
      "image 110/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame28_png.rf.b8c79869aa1d2c03a1f7a4bd8a540d0c.jpg: 640x640 1 Raising_Hand, 10.7ms\n",
      "image 111/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame36_png.rf.5601f633237b7a09bf3ac345d0973a83.jpg: 640x640 1 Raising_Hand, 11.4ms\n",
      "image 112/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame203_png.rf.1f192dafc6c2d5254f20d978d5686002.jpg: 640x640 1 Raising_Hand, 10.1ms\n",
      "image 113/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame204_png.rf.6e68d8179370565c072ed66f0689b0cb.jpg: 640x640 1 Raising_Hand, 11.6ms\n",
      "image 114/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame212_png.rf.d55343f0569daab52a4890575cb3810e.jpg: 640x640 1 Raising_Hand, 11.8ms\n",
      "image 115/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame213_png.rf.b03c30a0816e5964306b4024658f8939.jpg: 640x640 1 Raising_Hand, 13.4ms\n",
      "image 116/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame215_png.rf.fa7ec0ab5121ffc767f76e2debb85cfa.jpg: 640x640 1 Raising_Hand, 10.4ms\n",
      "image 117/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame218_png.rf.22c93d81dcdc72071ec156d43a8ab170.jpg: 640x640 1 Raising_Hand, 11.4ms\n",
      "image 118/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame229_png.rf.5b3f2431e34533b13c63e5133881696c.jpg: 640x640 1 Raising_Hand, 11.0ms\n",
      "image 119/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand05_rgb_1_frame222_png.rf.4a44445b3fb69cc2a10f2858958023d8.jpg: 640x640 1 Raising_Hand, 11.4ms\n",
      "image 120/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame102_png.rf.f75085213690436ec61c57c38227626c.jpg: 640x640 1 Raising_Hand, 10.3ms\n",
      "image 121/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame103_png.rf.14e4ebeabf04475336b5d33e3b6e51fa.jpg: 640x640 1 Raising_Hand, 13.2ms\n",
      "image 122/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame106_png.rf.9f71375f7cdab33ded0cdbedddc2d4fe.jpg: 640x640 1 Raising_Hand, 10.9ms\n",
      "image 123/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame109_png.rf.9b8e39c8679b5c39747b8aa4d7e579b1.jpg: 640x640 1 Raising_Hand, 10.7ms\n",
      "image 124/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame27_png.rf.2ee6d4b58aea75fd4137deb50fad6d25.jpg: 640x640 1 Raising_Hand, 10.8ms\n",
      "image 125/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame31_png.rf.2332bae29b6e7f384a88581b983cf6b7.jpg: 640x640 1 Raising_Hand, 10.4ms\n",
      "image 126/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame38_png.rf.f0e82d99c3be80985adffe9494d60694.jpg: 640x640 1 Raising_Hand, 12.3ms\n",
      "image 127/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame40_png.rf.975deb8feaad36bdc9b7e49a7ab759b8.jpg: 640x640 1 Raising_Hand, 11.0ms\n",
      "image 128/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame97_png.rf.1e261cc55a7feae8e6e934be2c90f939.jpg: 640x640 1 Raising_Hand, 10.6ms\n",
      "image 129/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame98_png.rf.524b1cba571db62dc9f8f703f932de3a.jpg: 640x640 1 Raising_Hand, 11.6ms\n",
      "image 130/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame26_png.rf.14c9f0161735532764d417ccbd4b8282.jpg: 640x640 1 Raising_Hand, 12.1ms\n",
      "image 131/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame34_png.rf.7567ceb24555a0fb510817992280e7a0.jpg: 640x640 1 Raising_Hand, 11.7ms\n",
      "image 132/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame35_png.rf.443d7bdf0a65df556ff75e36b59d8ff6.jpg: 640x640 1 Raising_Hand, 10.7ms\n",
      "image 133/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame38_png.rf.d18325c081bec9feb31528469efca337.jpg: 640x640 1 Raising_Hand, 12.3ms\n",
      "image 134/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame39_png.rf.5be5a902aab82384981a972a72d00b39.jpg: 640x640 1 Raising_Hand, 11.0ms\n",
      "image 135/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand13_rgb_1_frame129_png.rf.818c8fab0f32e4de1cceeb8b9740d90f.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 136/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame37_png.rf.5aa6658aada97f5ec95afdb99e5bfc63.jpg: 640x640 1 Raising_Hand, 12.7ms\n",
      "image 137/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame55_png.rf.4f521a852571a031f4f64b2af5ca632e.jpg: 640x640 1 Raising_Hand, 10.8ms\n",
      "image 138/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame153_png.rf.31c74561d71a24d43a210a36f3bfa64a.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 139/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame156_png.rf.96c528c0a5710919b9646b28562effa5.jpg: 640x640 1 Raising_Hand, 11.2ms\n",
      "image 140/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame160_png.rf.51a63336913d6132fcfd947a8a751cbd.jpg: 640x640 1 Raising_Hand, 12.3ms\n",
      "image 141/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame53_png.rf.4afb5029370c42d92a8aff7b1da69144.jpg: 640x640 1 Raising_Hand, 11.2ms\n",
      "image 142/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_1_frame63_png.rf.8838d4694e52be999ab5da8ef2b15fbe.jpg: 640x640 1 Raising_Hand, 10.8ms\n",
      "image 143/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame209_png.rf.a8cbc7452bdaf128d0f0c9c1bc2fb85c.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 144/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame214_png.rf.2684a5d44891746107cdb5d070da0c06.jpg: 640x640 1 Raising_Hand, 10.4ms\n",
      "image 145/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame218_png.rf.eec1f6aaec32df1e1eecedfd79779a0d.jpg: 640x640 1 Raising_Hand, 11.4ms\n",
      "image 146/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame148_png.rf.d8c52a54f0e09ba983cd7030d0b2b406.jpg: 640x640 1 Raising_Hand, 9.9ms\n",
      "image 147/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame154_png.rf.09e49195999dd8d6349847e8409e79f7.jpg: 640x640 1 Raising_Hand, 11.1ms\n",
      "image 148/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame22_png.rf.8160fcd1a15da7ea746f09b16c8065fe.jpg: 640x640 1 Raising_Hand, 11.9ms\n",
      "image 149/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame27_png.rf.e60f200187b98c10cda8ff0db0f7d759.jpg: 640x640 1 Raising_Hand, 13.0ms\n",
      "image 150/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame29_png.rf.693ecf1834ba96794b7c752b6f9dfca2.jpg: 640x640 1 Raising_Hand, 10.7ms\n",
      "image 151/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand23_rgb_2_frame221_png.rf.858b87da871b6b3bb036320f876b316a.jpg: 640x640 1 Raising_Hand, 10.4ms\n",
      "image 152/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame103_png.rf.687859f4a8f45acc9bf0aa328f1372ec.jpg: 640x640 1 Raising_Hand, 11.5ms\n",
      "image 153/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame92_png.rf.ff781ed0667b74b59e6a7b0ae1bb88e5.jpg: 640x640 1 Raising_Hand, 10.3ms\n",
      "image 154/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand40_rgb_3_frame45_png.rf.9df76ddb56a43cd141ca5bc911718fda.jpg: 640x640 1 Raising_Hand, 10.1ms\n",
      "image 155/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame171_png.rf.e04b9c3232f963952ac514777f6903be.jpg: 640x640 1 Reading, 10.4ms\n",
      "image 156/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame172_png.rf.b3be0ab18f47eb716fcc63061d708bce.jpg: 640x640 1 Reading, 13.2ms\n",
      "image 157/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame180_png.rf.66d6ec325102331a64ccc33c9474d50c.jpg: 640x640 1 Reading, 12.0ms\n",
      "image 158/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame48_png.rf.f2a4d133af5d6910a8ab772a448cfdee.jpg: 640x640 1 Reading, 11.1ms\n",
      "image 159/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame3_png.rf.3ad9beef2bd405f4a4e16f88fcc7871b.jpg: 640x640 1 Reading, 11.0ms\n",
      "image 160/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame59_png.rf.e4dfbfd5219bb1393efd3408d5d21681.jpg: 640x640 1 Reading, 12.5ms\n",
      "image 161/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_1_frame16_png.rf.da7c90f7a8b2257d1d97b7e3e580064b.jpg: 640x640 1 Reading, 12.3ms\n",
      "image 162/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame137_png.rf.63107347371d18af3084d3da3c482853.jpg: 640x640 1 Reading, 11.2ms\n",
      "image 163/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame173_png.rf.14f2feabf59ecf243fe61a76d50212d1.jpg: 640x640 1 Reading, 10.9ms\n",
      "image 164/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame179_png.rf.7f00ac8180ddb000b6d8aa2dd5be5352.jpg: 640x640 1 Reading, 11.3ms\n",
      "image 165/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame192_png.rf.e1c614ecde24b1999a5c91d892c5b181.jpg: 640x640 1 Reading, 10.0ms\n",
      "image 166/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame76_png.rf.55ac3124331cff8923984a7f874f575e.jpg: 640x640 1 Reading, 12.7ms\n",
      "image 167/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame79_png.rf.b3fb2a2379b7c6a996738dfcb442711c.jpg: 640x640 1 Reading, 10.6ms\n",
      "image 168/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame83_png.rf.4d2853e5659337c00525bcacef1d1d1f.jpg: 640x640 1 Reading, 11.2ms\n",
      "image 169/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame19_png.rf.d85b5e665ceafc964b581452fabb989e.jpg: 640x640 1 Reading, 11.4ms\n",
      "image 170/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame239_png.rf.836feeacfb43e83b96e31a6c1f7095d9.jpg: 640x640 1 Reading, 11.6ms\n",
      "image 171/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame28_png.rf.4d8bb6f2dcec05fc9b7f9730d995e069.jpg: 640x640 1 Reading, 11.5ms\n",
      "image 172/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame29_png.rf.280e2dfce72dd4b34eef4bb686fd663b.jpg: 640x640 1 Reading, 11.1ms\n",
      "image 173/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame10_png.rf.8a5e3f231a8c12083cce3b6d8a8a7047.jpg: 640x640 1 Reading, 10.1ms\n",
      "image 174/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame26_png.rf.2a84662f0b45f2b9e8834ab65b81e361.jpg: 640x640 1 Reading, 10.2ms\n",
      "image 175/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame27_png.rf.96e04fb3b3cae36ae3268e7946f38338.jpg: 640x640 1 Reading, 12.1ms\n",
      "image 176/226 d:\\research2\\classroom-attention\\data\\test\\images\\read13_rgb_3_frame204_png.rf.f0b6db3ba56942d451e99df0e014c7c3.jpg: 640x640 1 Reading, 11.5ms\n",
      "image 177/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_1_frame22_png.rf.01ec55b73b0bb9d3edb6285cb15fdf50.jpg: 640x640 1 Reading, 12.0ms\n",
      "image 178/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_4_frame3_png.rf.8bc93b6d3699e91bfd3e6899fdd85a4d.jpg: 640x640 1 Reading, 11.1ms\n",
      "image 179/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame117_png.rf.1f6cbfa8432f1638e543fcfd591ebee9.jpg: 640x640 1 Reading, 10.6ms\n",
      "image 180/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame119_png.rf.3662f8ba4bb01b5cf6b5cc7495b24d9b.jpg: 640x640 1 Reading, 11.5ms\n",
      "image 181/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame131_png.rf.34540fcf480ee68f8a612f8489523e11.jpg: 640x640 1 Reading, 10.4ms\n",
      "image 182/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame133_png.rf.127bdfc99254fe09060d247a27779fff.jpg: 640x640 1 Reading, 10.8ms\n",
      "image 183/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame143_png.rf.80bced075da7b2d5e7be3b0940d913b7.jpg: 640x640 1 Reading, 10.4ms\n",
      "image 184/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame242_png.rf.45e6abe238e2e66d088ddc00ffb8d366.jpg: 640x640 1 Reading, 12.3ms\n",
      "image 185/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame120_png.rf.4ff9286dee9cf53cf26a82ba8f170dd1.jpg: 640x640 1 Reading, 11.4ms\n",
      "image 186/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame57_png.rf.5ae953d3456e283a6965299d50161fc0.jpg: 640x640 1 Reading, 10.8ms\n",
      "image 187/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame225_png.rf.6a3c71cc2b11a9e9a04eba75221e71f8.jpg: 640x640 1 Reading, 13.6ms\n",
      "image 188/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame240_png.rf.e1a259e9c07e63e97f17927276770534.jpg: 640x640 1 Reading, 11.3ms\n",
      "image 189/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame10_png.rf.baa790d16c1be891a3e4d07abdaeacfd.jpg: 640x640 1 Reading, 9.9ms\n",
      "image 190/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame23_png.rf.a670b0b861cd69a80f56f31859727d1b.jpg: 640x640 1 Reading, 11.2ms\n",
      "image 191/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame14_png.rf.90a1b46716b4787d6ac73d8bbecf9367.jpg: 640x640 1 Reading, 11.5ms\n",
      "image 192/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame16_png.rf.60dbd8cba506f1bac0348c3100ce34b6.jpg: 640x640 1 Reading, 12.0ms\n",
      "image 193/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame26_png.rf.1bfe47aa92e0283f40ef62def13d74af.jpg: 640x640 1 Reading, 10.5ms\n",
      "image 194/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame350_png.rf.d3db8b8e8d96681456460d2c7d721e52.jpg: 640x640 1 Sleeping, 12.5ms\n",
      "image 195/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame365_png.rf.7b955e726b0e21927bee79809867e935.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 196/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame367_png.rf.8757710fd35f1cc3c071a70f34acf5d6.jpg: 640x640 1 Sleeping, 9.9ms\n",
      "image 197/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame381_png.rf.824acbd869aabe62b9c47e1b5e1b6aa8.jpg: 640x640 1 Sleeping, 14.0ms\n",
      "image 198/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame131_png.rf.0b9ff50aca0a9c4e720fd2fc019112a3.jpg: 640x640 1 Sleeping, 10.7ms\n",
      "image 199/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame132_png.rf.ae98929a07f07ca51e650b8c4330565b.jpg: 640x640 1 Sleeping, 12.3ms\n",
      "image 200/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep02_rgb_3_frame208_png.rf.8e5cea278e41d658979dc697bb4ee698.jpg: 640x640 1 Sleeping, 11.1ms\n",
      "image 201/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame10_png.rf.75992b953dacacc68a5d5a167c987f8a.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 202/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame6_png.rf.77fce1c8dc9c8ed7d78e6cda97f344e2.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 203/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_4_frame53_png.rf.03cea74d0449c98903ddf2f18bd0a76d.jpg: 640x640 1 Sleeping, 11.3ms\n",
      "image 204/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_1_frame7_png.rf.42c1ea116a511ab7f4cd9967858bdd63.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 205/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_3_frame2_png.rf.713fa271516429ffd48b702c4ec394f4.jpg: 640x640 1 Sleeping, 10.4ms\n",
      "image 206/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame491_png.rf.8d23c808b52aa0ba76114c8514438ad3.jpg: 640x640 1 Sleeping, 10.5ms\n",
      "image 207/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame499_png.rf.4a25a4b0a4738abb1b5f098d1d13a81f.jpg: 640x640 1 Sleeping, 12.3ms\n",
      "image 208/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame12_png.rf.00e6a56fc283463d91c5207b8e2abfea.jpg: 640x640 1 Sleeping, 10.4ms\n",
      "image 209/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame1_png.rf.fc729f7d8dab490d64600f2716c29eca.jpg: 640x640 1 Sleeping, 12.0ms\n",
      "image 210/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame5_png.rf.839270aea831b7bf95e401d3f921dca7.jpg: 640x640 1 Sleeping, 11.3ms\n",
      "image 211/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame14_png.rf.88fce954118467b425233cba75ed4d5e.jpg: 640x640 1 Sleeping, 11.2ms\n",
      "image 212/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame22_png.rf.e2680f4df744b654a8f8ad25898a96dc.jpg: 640x640 1 Sleeping, 10.6ms\n",
      "image 213/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame5_png.rf.03889e765cb346db5a9b11b4fa568011.jpg: 640x640 1 Sleeping, 11.9ms\n",
      "image 214/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_3_frame457_png.rf.38355f92db1797dcffdc4ad1ee85cc03.jpg: 640x640 1 Sleeping, 10.2ms\n",
      "image 215/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame16_png.rf.6512c41305f79fd3621ee84ac52beace.jpg: 640x640 1 Sleeping, 11.4ms\n",
      "image 216/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame5_png.rf.7211aaba76cc164190fcc0ece61f378c.jpg: 640x640 1 Sleeping, 11.0ms\n",
      "image 217/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep20_rgb_1_frame197_png.rf.56fbbc05973390d04699eef597b957b5.jpg: 640x640 1 Sleeping, 18.0ms\n",
      "image 218/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame295_png.rf.f4d3b3ca8ac0b3f1c72a884ae96c98f2.jpg: 640x640 1 Sleeping, 12.5ms\n",
      "image 219/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame306_png.rf.061aba5baac216e1d24330e7fbd51445.jpg: 640x640 1 Sleeping, 10.7ms\n",
      "image 220/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep25_rgb_1_frame3_png.rf.486a414ebb1ea6c8ac4ce613062a2447.jpg: 640x640 1 Sleeping, 14.1ms\n",
      "image 221/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame219_png.rf.a53caaf46f636872db9f6c96094dc345.jpg: 640x640 1 Sleeping, 10.6ms\n",
      "image 222/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame228_png.rf.9378688b6e21c581cd53d9c6dcdba410.jpg: 640x640 1 Sleeping, 10.8ms\n",
      "image 223/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame4_png.rf.867510b6586afde44bf821ac546d5e5e.jpg: 640x640 1 Sleeping, 11.5ms\n",
      "image 224/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame9_png.rf.5e8bff960fb897acc90df0fc49223c03.jpg: 640x640 1 Sleeping, 10.7ms\n",
      "image 225/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame13_png.rf.c313e943c01dc74cac17c3926236bc38.jpg: 640x640 1 Sleeping, 13.7ms\n",
      "image 226/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame4_png.rf.7f6a45dd314f42787b1a5d045c0e0cd1.jpg: 640x640 1 Sleeping, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov12m\\prediction_outputs\\yolov12m-pred\u001b[0m\n",
      "226 labels saved to yolov12m\\prediction_outputs\\yolov12m-pred\\labels\n",
      "\n",
      " Sample predictions saved in yolov12m\\prediction_outputs\\yolov12m-pred\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = 'models/yolo12m.pt'\n",
    "DATASET_YAML = 'data/data.yaml'\n",
    "\n",
    "TRAIN_PARAMS = {\n",
    "    'data': DATASET_YAML,\n",
    "    'epochs': 100,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'name': 'classroom_attention_yolov12m',\n",
    "    'project': 'yolov12m/train',\n",
    "    'workers': 4,\n",
    "    'optimizer': 'SGD',\n",
    "    'patience': 20,\n",
    "    'device': '0',\n",
    "    'save': True,\n",
    "    'exist_ok': True,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "def train_model(model_path, params):\n",
    "    print(f\"\\n Loading Model: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    print(\"Resolved model name:\", model.model_name)\n",
    "    \n",
    "    print(\"\\n Training Started...\\n\")\n",
    "    results = model.train(**params)\n",
    "    \n",
    "    print(\"\\n Training Complete!\")\n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model, dataset_yaml):\n",
    "    print(\"\\n Running validation on VALIDATION split...\\n\")\n",
    "    val_metrics = model.val(data=dataset_yaml, split='val')\n",
    "\n",
    "    print(\"\\n Validation Metrics:\")\n",
    "    print(f\"mAP50: {val_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {val_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {val_metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {val_metrics.box.mr:.4f}\")\n",
    "    plot_per_class_metrics(\n",
    "    val_metrics.box.p,\n",
    "    val_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov12m/evaluation_plots/validation/per_val_class_metrics.png'\n",
    ")\n",
    "    print(\"\\n Running validation on TEST split...\\n\")\n",
    "    test_metrics = model.val(data=dataset_yaml, split='test')\n",
    "\n",
    "    print(\"\\n Test Metrics:\")\n",
    "    print(f\"mAP50: {test_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {test_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {test_metrics.box.mp}\")\n",
    "    print(f\"Recall: {test_metrics.box.mr}\")\n",
    "    plot_per_class_metrics(\n",
    "    test_metrics.box.p,\n",
    "    test_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov12m/evaluation_plots/validation/per_test_class_metrics.png'\n",
    ")\n",
    "    return val_metrics, test_metrics\n",
    "\n",
    "\n",
    "def plot_metrics(metrics, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        map50 = metrics.box.map50\n",
    "        map95 = metrics.box.map\n",
    "        precision = metrics.box.mp\n",
    "        recall = metrics.box.mr\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(['mAP@50', 'mAP@50-95', 'Precision', 'Recall'],\n",
    "                [map50, map95, precision, recall],\n",
    "                color=['dodgerblue', 'teal', 'orange', 'tomato'])\n",
    "\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('Overall Detection Metrics')\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(save_dir, 'overall_metrics.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\" Metric plot saved to {plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error while plotting metrics: {e}\")\n",
    "\n",
    "\n",
    "def plot_training_loss_curves(run_dir='yolov12m/detect/exp', save_dir='yolov12m/training_plots'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results_path = os.path.join(run_dir, 'results.csv')\n",
    "    if not os.path.isfile(results_path):\n",
    "        print(f\" No results.csv found at {results_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "\n",
    "    # Plot available loss curves — check column names if needed\n",
    "    loss_keys = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plotted = False\n",
    "    for key in loss_keys:\n",
    "        if key in df.columns:\n",
    "            plt.plot(df.index, df[key], label=key)\n",
    "            plotted = True\n",
    "\n",
    "    if plotted:\n",
    "        plt.title(\"Training Loss Curves\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plot_path = os.path.join(save_dir, 'loss_curves.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" Training curves saved to {plot_path}\")\n",
    "    else:\n",
    "        print(\" No loss columns found in results.csv\")\n",
    "\n",
    "\n",
    "def plot_predictions(model, save_dir='yolov12m/prediction_outputs'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results = model.predict(\n",
    "        source=\"data/test/images\",\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        conf=0.25,\n",
    "        max_det=100,\n",
    "        project='yolov12m/prediction_outputs',\n",
    "        name='yolov12m-pred'\n",
    "    )\n",
    "    print(f\"\\n Sample predictions saved in {results[0].save_dir}\")\n",
    "\n",
    "def plot_per_class_metrics(precision, recall, class_names=None, save_path=None):\n",
    "    num_classes = len(precision)\n",
    "    indices = np.arange(num_classes)\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    width = 0.35  # Width of bars\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(indices - width/2, precision, width, label='Precision', color='skyblue')\n",
    "    plt.bar(indices + width/2, recall, width, label='Recall', color='salmon')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Per-Class Precision and Recall')\n",
    "    plt.xticks(indices, class_names, rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "model, train_results = train_model(MODEL_NAME, TRAIN_PARAMS)\n",
    "\n",
    "plot_training_loss_curves(run_dir='yolov12m/train/classroom_attention_yolov12m')\n",
    "\n",
    "val_metrics, test_metrics = evaluate_model(model, DATASET_YAML)\n",
    "plot_metrics(val_metrics, save_dir='yolov12m/evaluation_plots/validation')\n",
    "plot_metrics(test_metrics, save_dir='yolov12m/evaluation_plots/test')\n",
    "plot_predictions(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
