{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27297018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading Model: models/yolo11m.pt\n",
      "Resolved model name: models/yolo11m.pt\n",
      "\n",
      " Training Started...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=models/yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=classroom_attention_yolov11m, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolov11m/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolov11m\\train\\classroom_attention_yolov11m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1414879  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "YOLO11m summary: 231 layers, 20,056,863 parameters, 20,056,847 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.3 ms, read: 4.93.4 MB/s, size: 42.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\train\\labels.cache... 1583 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1583/1583 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 1.41.0 MB/s, size: 42.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolov11m\\train\\classroom_attention_yolov11m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1myolov11m\\train\\classroom_attention_yolov11m\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.82G     0.6629      1.798       1.33         46        640: 100%|██████████| 99/99 [00:22<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.837      0.897      0.978      0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      7.93G     0.5663     0.8828      1.209         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.578      0.685        0.7      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      7.94G     0.6138     0.8364      1.221         41        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.603      0.712      0.817      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      7.92G     0.6237     0.8288      1.232         45        640: 100%|██████████| 99/99 [00:19<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.852      0.776       0.88      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      7.93G     0.6133     0.7733      1.221         43        640: 100%|██████████| 99/99 [00:19<00:00,  4.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.872      0.966      0.983      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100       7.9G     0.6008     0.7433      1.212         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.902      0.829      0.977      0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      7.94G     0.5852     0.6939      1.204         53        640: 100%|██████████| 99/99 [00:19<00:00,  5.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.839      0.862      0.947      0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      7.94G     0.5817     0.6737      1.194         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.807      0.795      0.907      0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      7.93G     0.5779     0.6348      1.191         38        640: 100%|██████████| 99/99 [00:19<00:00,  5.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.819      0.854      0.908      0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100       7.9G     0.5733     0.6023      1.184         36        640: 100%|██████████| 99/99 [00:19<00:00,  5.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.967      0.984      0.994      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      7.94G      0.558     0.5799      1.174         41        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.96       0.96       0.99      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      7.94G     0.5434     0.5392      1.166         49        640: 100%|██████████| 99/99 [00:19<00:00,  5.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.894      0.939      0.974       0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      7.93G      0.543     0.5485       1.16         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.982      0.995      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100       7.9G     0.5411     0.5135      1.164         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.97      0.972      0.994      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      7.94G     0.5321     0.4939      1.159         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.97      0.964      0.992      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      7.94G     0.5227     0.4823      1.146         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.975      0.991      0.995      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      7.93G     0.5251     0.4854      1.147         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.893      0.893      0.989      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100       7.9G     0.5172     0.4597      1.149         35        640: 100%|██████████| 99/99 [00:19<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.931      0.995      0.995      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      7.94G       0.51     0.4299      1.143         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.986      0.977      0.994      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      7.94G     0.5008     0.4471      1.134         36        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.984       0.97      0.993      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      7.93G     0.5044     0.4409      1.135         41        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.977      0.982      0.995      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100       7.9G     0.4942     0.4156      1.124         40        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991       0.99      0.993      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      7.94G     0.4913     0.4084      1.123         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      7.94G     0.4984        0.4      1.132         46        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.999      0.995      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      7.93G     0.4899     0.4061       1.12         40        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.996      0.995      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100       7.9G     0.4835      0.385      1.119         50        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.994      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      7.94G     0.4811     0.3869      1.119         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991      0.997      0.994      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      7.94G     0.4796     0.3731      1.122         39        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.981      0.989      0.995      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      7.93G     0.4739     0.3745      1.112         39        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.997      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100       7.9G     0.4668     0.3663      1.109         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      7.94G     0.4694     0.3601      1.116         34        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.942      0.996      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      7.94G     0.4642     0.3453      1.102         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.996      0.995      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      7.93G     0.4664     0.3552      1.105         51        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.992      0.995      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100       7.9G     0.4703      0.342      1.108         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.981      0.982      0.995       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      7.94G     0.4515     0.3371      1.099         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.996      0.995      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      7.94G     0.4585     0.3312      1.095         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.993      0.995      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      7.93G     0.4459       0.33      1.094         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.996      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100       7.9G     0.4491     0.3271      1.109         49        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.997      0.995      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      7.94G     0.4451     0.3188      1.099         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.997      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      7.94G     0.4424     0.3152      1.098         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.995      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      7.93G     0.4438     0.3089      1.092         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100       7.9G     0.4463     0.3044        1.1         46        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.997      0.995      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      7.94G     0.4426     0.3094      1.093         46        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      7.94G     0.4405     0.3121      1.089         48        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.992       0.99      0.991      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      7.93G     0.4358     0.2911      1.093         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.998      0.995      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100       7.9G     0.4413     0.3043      1.096         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.998      0.995      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      7.94G     0.4387     0.2965      1.094         48        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993      0.995      0.994      0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      7.94G     0.4401     0.2982      1.093         40        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      7.93G     0.4271     0.2965      1.093         49        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995      0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100       7.9G     0.4271     0.2833      1.084         50        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.998      0.995      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      7.94G     0.4326     0.2782      1.093         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.998      0.995      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      7.94G     0.4334     0.2899       1.09         50        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.996      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      7.93G     0.4208     0.2828      1.076         46        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.992          1      0.995      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100       7.9G     0.4263      0.275      1.084         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      7.94G     0.4098     0.2714      1.077         41        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.997      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      7.94G     0.4122     0.2623      1.079         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.998      0.995      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      7.93G     0.4122     0.2618      1.077         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.994      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100       7.9G      0.408     0.2689      1.075         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.994      0.995      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      7.94G     0.4124     0.2717      1.082         48        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.998      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      7.94G     0.4118     0.2587      1.074         49        640: 100%|██████████| 99/99 [00:19<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      7.93G     0.4029      0.248       1.07         39        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.985          1      0.995      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100       7.9G     0.3986     0.2524      1.071         51        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      7.94G     0.4072     0.2537       1.07         39        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.993      0.995      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      7.94G      0.396     0.2467      1.069         46        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.993      0.995      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      7.93G     0.4058     0.2506      1.071         38        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100       7.9G      0.392     0.2436      1.062         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.996      0.995      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      7.94G     0.3922     0.2441      1.064         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.998      0.995      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      7.94G     0.3981      0.251      1.065         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.995      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      7.93G       0.39      0.244       1.06         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100       7.9G     0.3858     0.2365       1.06         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.996      0.995      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      7.94G       0.39     0.2424      1.066         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.994      0.994      0.991      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      7.94G     0.3848     0.2315      1.053         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991          1      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      7.93G     0.3905     0.2373      1.066         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.994      0.991      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100       7.9G     0.3855     0.2294       1.06         38        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993      0.994      0.994       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      7.94G     0.3871     0.2306      1.065         41        640: 100%|██████████| 99/99 [00:19<00:00,  5.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.995      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      7.94G     0.3795     0.2374       1.06         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      7.93G     0.3754     0.2265       1.05         47        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995          1      0.995      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100       7.9G     0.3767     0.2259      1.055         44        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.995      0.995      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      7.94G     0.3695      0.227      1.055         52        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      7.94G     0.3669     0.2245      1.049         37        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997          1      0.995      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      7.93G     0.3664     0.2194      1.049         52        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.994      0.995      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100       7.9G     0.3695     0.2169      1.054         51        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.994      0.995      0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      7.94G     0.3679     0.2152      1.049         42        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.996      0.994      0.995      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      7.94G     0.3644     0.2132      1.053         43        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.994      0.995      0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      7.93G      0.365     0.2136      1.049         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100       7.9G     0.3636     0.2127       1.05         48        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.993          1      0.993      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      7.94G      0.354     0.2105      1.045         48        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.991          1      0.994       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      7.94G     0.3549     0.2051      1.046         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453       0.99          1      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      7.93G     0.3517     0.1997      1.046         35        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.995      0.995      0.995       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100       7.9G     0.3542     0.2013      1.044         45        640: 100%|██████████| 99/99 [00:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      7.94G     0.2169     0.1974      1.051         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      7.94G     0.2143      0.128       1.04         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.997      0.994      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      7.93G     0.2118     0.1198      1.041         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100       7.9G     0.2053     0.1118      1.038         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999      0.999      0.995      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      7.94G      0.205     0.1132      1.037         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998      0.999      0.995      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      7.94G     0.1951     0.1058      1.045         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      7.93G     0.1977     0.1058      1.032         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100       7.9G     0.1914     0.1019      1.027         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      7.94G     0.1944     0.1079      1.035         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      7.94G     0.1878     0.1034      1.032         15        640: 100%|██████████| 99/99 [00:19<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.998          1      0.995      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.645 hours.\n",
      "Optimizer stripped from yolov11m\\train\\classroom_attention_yolov11m\\weights\\last.pt, 40.5MB\n",
      "Optimizer stripped from yolov11m\\train\\classroom_attention_yolov11m\\weights\\best.pt, 40.5MB\n",
      "\n",
      "Validating yolov11m\\train\\classroom_attention_yolov11m\\weights\\best.pt...\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,033,887 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.947\n",
      "       Looking_Forward        101        101          1          1      0.995      0.958\n",
      "          Raising_Hand         96         96      0.999          1      0.995      0.952\n",
      "               Reading         73         73          1          1      0.995      0.955\n",
      "              Sleeping         81         81      0.998          1      0.995      0.936\n",
      "        Turning_Around        102        102      0.998          1      0.995      0.936\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1myolov11m\\train\\classroom_attention_yolov11m\u001b[0m\n",
      "\n",
      " Training Complete!\n",
      " Training curves saved to yolov11m/training_plots\\loss_curves.png\n",
      "\n",
      " Running validation on VALIDATION split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,033,887 parameters, 0 gradients, 67.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 599.974.9 MB/s, size: 40.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\valid\\labels.cache... 453 images, 0 backgrounds, 0 corrupt: 100%|██████████| 453/453 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 29/29 [00:03<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        453        453      0.999          1      0.995      0.947\n",
      "       Looking_Forward        101        101          1          1      0.995      0.957\n",
      "          Raising_Hand         96         96      0.999          1      0.995      0.952\n",
      "               Reading         73         73          1          1      0.995      0.955\n",
      "              Sleeping         81         81      0.998          1      0.995      0.936\n",
      "        Turning_Around        102        102      0.998          1      0.995      0.937\n",
      "Speed: 0.2ms preprocess, 5.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1myolov11m\\train\\classroom_attention_yolov11m\u001b[0m\n",
      "\n",
      " Validation Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9473\n",
      "Precision: 0.9991\n",
      "Recall: 1.0000\n",
      "Saved plot to yolov11m/evaluation_plots/validation/per_val_class_metrics.png\n",
      "\n",
      " Running validation on TEST split...\n",
      "\n",
      "Ultralytics 8.3.168  Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.34.6 ms, read: 2.41.2 MB/s, size: 41.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\research2\\classroom-attention\\data\\test\\labels.cache... 226 images, 0 backgrounds, 0 corrupt: 100%|██████████| 226/226 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        226        226      0.998          1      0.995      0.939\n",
      "       Looking_Forward         36         36      0.996          1      0.995      0.967\n",
      "          Raising_Hand         64         64          1          1      0.995      0.948\n",
      "               Reading         39         39      0.996          1      0.995      0.946\n",
      "              Sleeping         33         33      0.996          1      0.995      0.935\n",
      "        Turning_Around         54         54      0.999          1      0.995      0.901\n",
      "Speed: 0.3ms preprocess, 7.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1myolov11m\\train\\classroom_attention_yolov11m\u001b[0m\n",
      "\n",
      " Test Metrics:\n",
      "mAP50: 0.9950\n",
      "mAP50-95: 0.9393\n",
      "Precision: 0.9975185871978084\n",
      "Recall: 1.0\n",
      "Saved plot to yolov11m/evaluation_plots/validation/per_test_class_metrics.png\n",
      " Metric plot saved to yolov11m/evaluation_plots/validation\\overall_metrics.png\n",
      " Metric plot saved to yolov11m/evaluation_plots/test\\overall_metrics.png\n",
      "\n",
      "image 1/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame109_png.rf.b654c8e2b61f8a6225af75571f5a02e2.jpg: 640x640 1 Turning_Around, 15.9ms\n",
      "image 2/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame125_png.rf.d716870a273e655de1f58987b32a366f.jpg: 640x640 1 Turning_Around, 15.9ms\n",
      "image 3/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame133_png.rf.a1d1e40193045cb2d73a508fcd2aeffb.jpg: 640x640 1 Turning_Around, 17.1ms\n",
      "image 4/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame135_png.rf.5fbfdd53694f8987c732ed7fedf2fbf0.jpg: 640x640 1 Turning_Around, 16.9ms\n",
      "image 5/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame17_png.rf.aeb1ef619d24e07b33a9b3875f2ee150.jpg: 640x640 1 Turning_Around, 19.2ms\n",
      "image 6/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame19_png.rf.4eafdeb61da26cc04e2fa644eb60365b.jpg: 640x640 1 Turning_Around, 17.6ms\n",
      "image 7/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame22_png.rf.6d8036a863a8c6c7ce3a48b582c86fad.jpg: 640x640 1 Turning_Around, 18.0ms\n",
      "image 8/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame5_png.rf.bfe5c71a6f4cde8c92061a09dcb28b49.jpg: 640x640 1 Turning_Around, 18.2ms\n",
      "image 9/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_1_frame70_png.rf.53755b2c4fe579df00539e10ef45350a.jpg: 640x640 1 Turning_Around, 17.1ms\n",
      "image 10/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame146_png.rf.b749d7f39de2d04a0b8248221af7597e.jpg: 640x640 1 Turning_Around, 18.3ms\n",
      "image 11/226 d:\\research2\\classroom-attention\\data\\test\\images\\around02_rgb_2_frame148_png.rf.961d726e5b4c9a1a08ae22c1f6dbe97d.jpg: 640x640 1 Turning_Around, 19.7ms\n",
      "image 12/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame103_png.rf.01ce420b94d0afb7ad3b63db3bb6f770.jpg: 640x640 1 Turning_Around, 17.6ms\n",
      "image 13/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame105_png.rf.af0271387ab1b7b7cf12ca957d6604c6.jpg: 640x640 1 Turning_Around, 17.8ms\n",
      "image 14/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame106_png.rf.6c30ed12b539cd4b60ae6763eeb8f314.jpg: 640x640 1 Turning_Around, 18.1ms\n",
      "image 15/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame224_png.rf.a61153714fd35c3dfa0b07860b442207.jpg: 640x640 1 Turning_Around, 13.1ms\n",
      "image 16/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame256_png.rf.4fbf0d7449f4e9b8575806f9db8eacfe.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 17/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame31_png.rf.6b0f54e2b6a03b201b0b92a17209a627.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 18/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame34_png.rf.4c930225326fddbc1d4374de3582e2b6.jpg: 640x640 1 Turning_Around, 10.1ms\n",
      "image 19/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame89_png.rf.56d3efe6023447f36212d5de407db28e.jpg: 640x640 1 Turning_Around, 11.1ms\n",
      "image 20/226 d:\\research2\\classroom-attention\\data\\test\\images\\around03_rgb_1_frame95_png.rf.665bb5e0b1cef7ae2823cbd42f05c342.jpg: 640x640 1 Turning_Around, 10.6ms\n",
      "image 21/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame13_png.rf.a711450469f8a1091fe19c32566aa238.jpg: 640x640 1 Turning_Around, 10.4ms\n",
      "image 22/226 d:\\research2\\classroom-attention\\data\\test\\images\\around04_rgb_2_frame5_png.rf.5eba38da13096817f096b5095e301f31.jpg: 640x640 1 Turning_Around, 11.6ms\n",
      "image 23/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame125_png.rf.9cd8209af1c40444c37d713a37ee6ada.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 24/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame129_png.rf.15dbfd4b5e038a9d7df1445fcd0158d5.jpg: 640x640 1 Turning_Around, 10.3ms\n",
      "image 25/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_2_frame220_png.rf.a182febf26d1063ab084b18b54176579.jpg: 640x640 1 Turning_Around, 9.2ms\n",
      "image 26/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame110_png.rf.8549546e1fdbca99ef9bafd306a7b9b7.jpg: 640x640 1 Turning_Around, 9.2ms\n",
      "image 27/226 d:\\research2\\classroom-attention\\data\\test\\images\\around05_rgb_4_frame99_png.rf.90ba905fbcf0a76725030075aa2a091e.jpg: 640x640 1 Turning_Around, 8.6ms\n",
      "image 28/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame105_png.rf.4939150bdf70b55c6a63b4273eb91302.jpg: 640x640 1 Turning_Around, 9.4ms\n",
      "image 29/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame106_png.rf.c3954f46abf533c03cd76aaf82cc2dd1.jpg: 640x640 1 Turning_Around, 10.1ms\n",
      "image 30/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame107_png.rf.a07b8145e09f8ca45d29c841b712a621.jpg: 640x640 1 Turning_Around, 9.4ms\n",
      "image 31/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame119_png.rf.42b83b11b10f0dfc3abb1972a215e56b.jpg: 640x640 1 Turning_Around, 9.3ms\n",
      "image 32/226 d:\\research2\\classroom-attention\\data\\test\\images\\around06_rgb_1_frame124_png.rf.31dc5b02e3c494652afcf6cb10009d17.jpg: 640x640 1 Turning_Around, 10.9ms\n",
      "image 33/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame25_png.rf.fa0159593b6cac9f28d10e7ebd205f6d.jpg: 640x640 1 Turning_Around, 9.3ms\n",
      "image 34/226 d:\\research2\\classroom-attention\\data\\test\\images\\around07_rgb_1_frame30_png.rf.7dadf09e5a45356884473213872c6142.jpg: 640x640 1 Turning_Around, 8.3ms\n",
      "image 35/226 d:\\research2\\classroom-attention\\data\\test\\images\\around09_rgb_1_frame70_png.rf.cab1fde2fe507aee7b9304c32db1c1a2.jpg: 640x640 1 Turning_Around, 8.0ms\n",
      "image 36/226 d:\\research2\\classroom-attention\\data\\test\\images\\around10_rgb_2_frame60_png.rf.275960ae1818d569f11600b90a6dfdb1.jpg: 640x640 1 Turning_Around, 9.4ms\n",
      "image 37/226 d:\\research2\\classroom-attention\\data\\test\\images\\around11_rgb_1_frame265_png.rf.610a31ab8fd2844bf0e4757e840ddf6f.jpg: 640x640 1 Turning_Around, 8.5ms\n",
      "image 38/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame191_png.rf.4b4306bb38698f6e6b83acc57083d0dc.jpg: 640x640 1 Turning_Around, 9.4ms\n",
      "image 39/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame195_png.rf.ffd60ef2677deb02437b6e8779596e95.jpg: 640x640 1 Turning_Around, 9.7ms\n",
      "image 40/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame208_png.rf.302af784d70f73bd9331c8d79a070ac1.jpg: 640x640 1 Turning_Around, 8.9ms\n",
      "image 41/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame212_png.rf.d9651e1031ad13cbe2fb362e649b8fdc.jpg: 640x640 1 Turning_Around, 9.0ms\n",
      "image 42/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame271_png.rf.5e20e287b7c0ad3fcb1888cfbd291ae5.jpg: 640x640 1 Turning_Around, 9.7ms\n",
      "image 43/226 d:\\research2\\classroom-attention\\data\\test\\images\\around12_rgb_2_frame289_png.rf.f459b40af8180d7c25f7363063ad0f04.jpg: 640x640 1 Turning_Around, 9.5ms\n",
      "image 44/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame15_png.rf.bec9cf8151bb46c295ae6391f194aa31.jpg: 640x640 1 Turning_Around, 8.9ms\n",
      "image 45/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame3_png.rf.57fb58176870090ef700d642cd94bafc.jpg: 640x640 1 Turning_Around, 9.2ms\n",
      "image 46/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame4_png.rf.0760bfb18fcbde92e29ea2aa004156a7.jpg: 640x640 1 Turning_Around, 9.2ms\n",
      "image 47/226 d:\\research2\\classroom-attention\\data\\test\\images\\around13_rgb_1_frame7_png.rf.b9bd031365d6a9f1881d25f7c8847f07.jpg: 640x640 1 Turning_Around, 10.3ms\n",
      "image 48/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame5_png.rf.975a814bcfef05a0640e15e3ec9f7c4c.jpg: 640x640 1 Turning_Around, 8.5ms\n",
      "image 49/226 d:\\research2\\classroom-attention\\data\\test\\images\\around14_rgb_1_frame7_png.rf.a2f065b02c7363a7e6140691aeb0b16f.jpg: 640x640 1 Turning_Around, 11.0ms\n",
      "image 50/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame141_png.rf.97f861930be1e79d87618ce8027ead0a.jpg: 640x640 1 Turning_Around, 8.8ms\n",
      "image 51/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame156_png.rf.dfaf9cafde4c8b4312f416173295593f.jpg: 640x640 1 Turning_Around, 9.4ms\n",
      "image 52/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame187_png.rf.1ca23609e719f17d5ddd0fc10babccec.jpg: 640x640 1 Turning_Around, 9.0ms\n",
      "image 53/226 d:\\research2\\classroom-attention\\data\\test\\images\\around16_rgb_1_frame192_png.rf.36cae9e67abda01ef56fe60ca9f4396c.jpg: 640x640 1 Turning_Around, 9.3ms\n",
      "image 54/226 d:\\research2\\classroom-attention\\data\\test\\images\\around17_rgb_1_frame130_png.rf.83f2f559afb812db78df93db294b1172.jpg: 640x640 1 Turning_Around, 9.6ms\n",
      "image 55/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame1_png.rf.99455f04937225c791a09b5d3bd15431.jpg: 640x640 1 Looking_Forward, 9.9ms\n",
      "image 56/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward01_rgb_4_frame4_png.rf.7d1ad65a527838d23798337da1ef499d.jpg: 640x640 1 Looking_Forward, 10.0ms\n",
      "image 57/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_1_frame1_png.rf.3d03883d2917b358b043e5bbda2c70f1.jpg: 640x640 1 Looking_Forward, 9.8ms\n",
      "image 58/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_2_frame180_png.rf.a64a769c1cd562224bf5909213d55dad.jpg: 640x640 1 Looking_Forward, 9.2ms\n",
      "image 59/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward02_rgb_4_frame60_png.rf.56ff5c31159577f9694dcd5641fc39f9.jpg: 640x640 1 Looking_Forward, 9.3ms\n",
      "image 60/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame148_png.rf.3f8e7e14dd62fb37f887ded1a22791c5.jpg: 640x640 1 Looking_Forward, 9.2ms\n",
      "image 61/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame153_png.rf.c6a2f8fa39a609eb9c5c31100ac8a792.jpg: 640x640 1 Looking_Forward, 10.2ms\n",
      "image 62/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame159_png.rf.02a525d0331074da812ea53ad01f1ecb.jpg: 640x640 1 Looking_Forward, 8.9ms\n",
      "image 63/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward03_rgb_1_frame4_png.rf.d793dadcaece19329dc8facc04ba2d3f.jpg: 640x640 1 Looking_Forward, 10.5ms\n",
      "image 64/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward04_rgb_2_frame299_png.rf.8784d9853b59961a38f76ae71e9fe178.jpg: 640x640 1 Looking_Forward, 9.6ms\n",
      "image 65/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_1_frame56_png.rf.1a9a50372478e06bd2716b0557829106.jpg: 640x640 1 Looking_Forward, 12.5ms\n",
      "image 66/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_3_frame4_png.rf.cd911f7a30af8a17dbf5c27d95905f50.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 67/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame13_png.rf.39c7fe3c32b3dc57560aa09c8eb7a877.jpg: 640x640 1 Looking_Forward, 10.3ms\n",
      "image 68/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward07_rgb_4_frame15_png.rf.3d77a4502b13e0aba4ed9c3cb2e4e8a7.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 69/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame18_png.rf.ccf95059cc8227952e07945e38c6eb62.jpg: 640x640 1 Looking_Forward, 22.4ms\n",
      "image 70/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward09_rgb_4_frame6_png.rf.3c0205ac3335ea8f994da934491721db.jpg: 640x640 1 Looking_Forward, 13.9ms\n",
      "image 71/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward10_rgb_4_frame130_png.rf.1af82e3fdda24c16614eb09f35d1eda7.jpg: 640x640 1 Looking_Forward, 10.7ms\n",
      "image 72/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame258_png.rf.0ef83b8f2042a34cfde49412bcf2a748.jpg: 640x640 1 Looking_Forward, 10.7ms\n",
      "image 73/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame265_png.rf.dfae9b01727c2bc2ce5130f4c3cbbbff.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 74/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame276_png.rf.a5aa19bd1502964c9b0caaf4e9e814dd.jpg: 640x640 1 Looking_Forward, 10.7ms\n",
      "image 75/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward13_rgb_1_frame282_png.rf.6bd8b44d0fbe89059e380ee2d62869ac.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 76/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame15_png.rf.4ba9de73214319ee38354c2146b13ca4.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 77/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward16_rgb_4_frame31_png.rf.c2e1ff1e14127ba20742f613d6eadb65.jpg: 640x640 1 Looking_Forward, 10.3ms\n",
      "image 78/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward17_rgb_4_frame265_png.rf.bccb08fba9349bdf56113abd3660d51f.jpg: 640x640 1 Looking_Forward, 10.3ms\n",
      "image 79/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame274_png.rf.1021e3e1cc279a54889b946527f11a03.jpg: 640x640 1 Looking_Forward, 10.1ms\n",
      "image 80/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame275_png.rf.c38c06abc3b62b3eb4ded600dd980332.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 81/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame294_png.rf.01170f58bab5570f5a6cd45f9fb0eb10.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 82/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward20_rgb_1_frame298_png.rf.cc7d9b262ad63612836c4dc6a6d52c75.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 83/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward22_rgb_4_frame4_png.rf.8cbd9b4e68c5e2bd6a70f63476431c97.jpg: 640x640 1 Looking_Forward, 10.6ms\n",
      "image 84/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward24_rgb_2_frame84_png.rf.e7df7f15b708bca038c57c6a4b1a9b52.jpg: 640x640 1 Looking_Forward, 9.9ms\n",
      "image 85/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame52_png.rf.8d87aa607ef9e6eeefa1db35104e2e8c.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 86/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame63_png.rf.75bf91bde83601e65e2cf30f2954a0ec.jpg: 640x640 1 Looking_Forward, 11.1ms\n",
      "image 87/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame69_png.rf.cbd26db73ae8fe499237c032c0509b60.jpg: 640x640 1 Looking_Forward, 10.4ms\n",
      "image 88/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame75_png.rf.7b06e46d9e4e2baa38642418f6216e23.jpg: 640x640 1 Looking_Forward, 10.1ms\n",
      "image 89/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward27_rgb_2_frame76_png.rf.dc32bd12625090c2aae0d5874e2f4c8f.jpg: 640x640 1 Looking_Forward, 11.6ms\n",
      "image 90/226 d:\\research2\\classroom-attention\\data\\test\\images\\forward30_rgb_1_frame94_png.rf.3c04241c702d3873763a6b4e767d9507.jpg: 640x640 1 Looking_Forward, 11.9ms\n",
      "image 91/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame100_png.rf.0308d2b0dd3c54b5cfe95ad0bb96c48b.jpg: 640x640 1 Raising_Hand, 8.2ms\n",
      "image 92/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame71_png.rf.9d06c50933c7a04230860c6401a2a5c5.jpg: 640x640 1 Raising_Hand, 10.8ms\n",
      "image 93/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame84_png.rf.289a5a0af22bf40f32f16feab04f5f50.jpg: 640x640 1 Raising_Hand, 10.6ms\n",
      "image 94/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame89_png.rf.33131c2876ba81af06ebfbf95758e932.jpg: 640x640 1 Raising_Hand, 14.6ms\n",
      "image 95/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_1_frame99_png.rf.de17495fd1af4d7530f950374b1f6933.jpg: 640x640 1 Raising_Hand, 8.3ms\n",
      "image 96/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame193_png.rf.076f557cf5122a255c2b5c2446f11da0.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 97/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame196_png.rf.f18ba7130a6d28f3bb7b3608136e8837.jpg: 640x640 1 Raising_Hand, 10.7ms\n",
      "image 98/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame200_png.rf.8ccf8edc5b06faa1a410e58e75b905eb.jpg: 640x640 1 Raising_Hand, 9.4ms\n",
      "image 99/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame202_png.rf.dfbeee2974446dceb27d88fcf3aaaeba.jpg: 640x640 1 Raising_Hand, 9.4ms\n",
      "image 100/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame21_png.rf.a81a23d39c13e837f5fa77059c731fde.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 101/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame29_png.rf.d3a268ae3eed65e4ec1b676a7c9f4784.jpg: 640x640 1 Raising_Hand, 8.9ms\n",
      "image 102/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand01_rgb_2_frame338_png.rf.61918b30a745a0bb42be8392a64dbb5b.jpg: 640x640 1 Raising_Hand, 9.1ms\n",
      "image 103/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame162_png.rf.37341cc74dd8a4d6f97121a6c0c530fe.jpg: 640x640 1 Raising_Hand, 9.1ms\n",
      "image 104/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame174_png.rf.c35f8f2b89efc9d4bcb405bc19286c25.jpg: 640x640 1 Raising_Hand, 8.7ms\n",
      "image 105/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_1_frame179_png.rf.6a9eddd503d1fc74e011e8496ea90ae4.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 106/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame187_png.rf.1d02d9dd3e8071002eef6d794fe06e60.jpg: 640x640 1 Raising_Hand, 8.8ms\n",
      "image 107/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand02_rgb_2_frame190_png.rf.271396f792b082080ea9849eac4d4432.jpg: 640x640 1 Raising_Hand, 9.8ms\n",
      "image 108/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame17_png.rf.ce8f1c6796509ad1454ba32803302ee1.jpg: 640x640 1 Raising_Hand, 9.8ms\n",
      "image 109/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame27_png.rf.fa2e3fdad51614c293915bad6547c947.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 110/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame28_png.rf.b8c79869aa1d2c03a1f7a4bd8a540d0c.jpg: 640x640 1 Raising_Hand, 8.4ms\n",
      "image 111/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand03_rgb_1_frame36_png.rf.5601f633237b7a09bf3ac345d0973a83.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 112/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame203_png.rf.1f192dafc6c2d5254f20d978d5686002.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 113/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame204_png.rf.6e68d8179370565c072ed66f0689b0cb.jpg: 640x640 1 Raising_Hand, 9.5ms\n",
      "image 114/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame212_png.rf.d55343f0569daab52a4890575cb3810e.jpg: 640x640 1 Raising_Hand, 10.2ms\n",
      "image 115/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame213_png.rf.b03c30a0816e5964306b4024658f8939.jpg: 640x640 1 Raising_Hand, 9.7ms\n",
      "image 116/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame215_png.rf.fa7ec0ab5121ffc767f76e2debb85cfa.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 117/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame218_png.rf.22c93d81dcdc72071ec156d43a8ab170.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 118/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand04_rgb_1_frame229_png.rf.5b3f2431e34533b13c63e5133881696c.jpg: 640x640 1 Raising_Hand, 8.9ms\n",
      "image 119/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand05_rgb_1_frame222_png.rf.4a44445b3fb69cc2a10f2858958023d8.jpg: 640x640 1 Raising_Hand, 8.5ms\n",
      "image 120/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame102_png.rf.f75085213690436ec61c57c38227626c.jpg: 640x640 1 Raising_Hand, 8.4ms\n",
      "image 121/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame103_png.rf.14e4ebeabf04475336b5d33e3b6e51fa.jpg: 640x640 1 Raising_Hand, 8.7ms\n",
      "image 122/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame106_png.rf.9f71375f7cdab33ded0cdbedddc2d4fe.jpg: 640x640 1 Raising_Hand, 9.1ms\n",
      "image 123/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand06_rgb_1_frame109_png.rf.9b8e39c8679b5c39747b8aa4d7e579b1.jpg: 640x640 1 Raising_Hand, 9.1ms\n",
      "image 124/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame27_png.rf.2ee6d4b58aea75fd4137deb50fad6d25.jpg: 640x640 1 Raising_Hand, 9.9ms\n",
      "image 125/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame31_png.rf.2332bae29b6e7f384a88581b983cf6b7.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 126/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame38_png.rf.f0e82d99c3be80985adffe9494d60694.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 127/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand10_rgb_4_frame40_png.rf.975deb8feaad36bdc9b7e49a7ab759b8.jpg: 640x640 1 Raising_Hand, 8.7ms\n",
      "image 128/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame97_png.rf.1e261cc55a7feae8e6e934be2c90f939.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 129/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand11_rgb_4_frame98_png.rf.524b1cba571db62dc9f8f703f932de3a.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 130/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame26_png.rf.14c9f0161735532764d417ccbd4b8282.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 131/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame34_png.rf.7567ceb24555a0fb510817992280e7a0.jpg: 640x640 1 Raising_Hand, 8.4ms\n",
      "image 132/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame35_png.rf.443d7bdf0a65df556ff75e36b59d8ff6.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 133/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame38_png.rf.d18325c081bec9feb31528469efca337.jpg: 640x640 1 Raising_Hand, 9.9ms\n",
      "image 134/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand12_rgb_4_frame39_png.rf.5be5a902aab82384981a972a72d00b39.jpg: 640x640 1 Raising_Hand, 8.5ms\n",
      "image 135/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand13_rgb_1_frame129_png.rf.818c8fab0f32e4de1cceeb8b9740d90f.jpg: 640x640 1 Raising_Hand, 9.8ms\n",
      "image 136/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame37_png.rf.5aa6658aada97f5ec95afdb99e5bfc63.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 137/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand14_rgb_2_frame55_png.rf.4f521a852571a031f4f64b2af5ca632e.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 138/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame153_png.rf.31c74561d71a24d43a210a36f3bfa64a.jpg: 640x640 1 Raising_Hand, 8.4ms\n",
      "image 139/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame156_png.rf.96c528c0a5710919b9646b28562effa5.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 140/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame160_png.rf.51a63336913d6132fcfd947a8a751cbd.jpg: 640x640 1 Raising_Hand, 8.4ms\n",
      "image 141/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand16_rgb_2_frame53_png.rf.4afb5029370c42d92a8aff7b1da69144.jpg: 640x640 1 Raising_Hand, 9.0ms\n",
      "image 142/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_1_frame63_png.rf.8838d4694e52be999ab5da8ef2b15fbe.jpg: 640x640 1 Raising_Hand, 9.8ms\n",
      "image 143/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame209_png.rf.a8cbc7452bdaf128d0f0c9c1bc2fb85c.jpg: 640x640 1 Raising_Hand, 9.8ms\n",
      "image 144/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame214_png.rf.2684a5d44891746107cdb5d070da0c06.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 145/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand21_rgb_2_frame218_png.rf.eec1f6aaec32df1e1eecedfd79779a0d.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 146/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame148_png.rf.d8c52a54f0e09ba983cd7030d0b2b406.jpg: 640x640 1 Raising_Hand, 8.5ms\n",
      "image 147/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame154_png.rf.09e49195999dd8d6349847e8409e79f7.jpg: 640x640 1 Raising_Hand, 9.6ms\n",
      "image 148/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame22_png.rf.8160fcd1a15da7ea746f09b16c8065fe.jpg: 640x640 1 Raising_Hand, 8.6ms\n",
      "image 149/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame27_png.rf.e60f200187b98c10cda8ff0db0f7d759.jpg: 640x640 1 Raising_Hand, 8.5ms\n",
      "image 150/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand22_rgb_2_frame29_png.rf.693ecf1834ba96794b7c752b6f9dfca2.jpg: 640x640 1 Raising_Hand, 9.3ms\n",
      "image 151/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand23_rgb_2_frame221_png.rf.858b87da871b6b3bb036320f876b316a.jpg: 640x640 1 Raising_Hand, 9.1ms\n",
      "image 152/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame103_png.rf.687859f4a8f45acc9bf0aa328f1372ec.jpg: 640x640 1 Raising_Hand, 8.7ms\n",
      "image 153/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand29_rgb_3_frame92_png.rf.ff781ed0667b74b59e6a7b0ae1bb88e5.jpg: 640x640 1 Raising_Hand, 8.8ms\n",
      "image 154/226 d:\\research2\\classroom-attention\\data\\test\\images\\hand40_rgb_3_frame45_png.rf.9df76ddb56a43cd141ca5bc911718fda.jpg: 640x640 1 Raising_Hand, 9.9ms\n",
      "image 155/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame171_png.rf.e04b9c3232f963952ac514777f6903be.jpg: 640x640 1 Reading, 8.8ms\n",
      "image 156/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame172_png.rf.b3be0ab18f47eb716fcc63061d708bce.jpg: 640x640 1 Reading, 8.8ms\n",
      "image 157/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame180_png.rf.66d6ec325102331a64ccc33c9474d50c.jpg: 640x640 1 Reading, 9.7ms\n",
      "image 158/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_1_frame48_png.rf.f2a4d133af5d6910a8ab772a448cfdee.jpg: 640x640 1 Reading, 8.2ms\n",
      "image 159/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame3_png.rf.3ad9beef2bd405f4a4e16f88fcc7871b.jpg: 640x640 1 Reading, 9.7ms\n",
      "image 160/226 d:\\research2\\classroom-attention\\data\\test\\images\\read02_rgb_4_frame59_png.rf.e4dfbfd5219bb1393efd3408d5d21681.jpg: 640x640 1 Reading, 11.0ms\n",
      "image 161/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_1_frame16_png.rf.da7c90f7a8b2257d1d97b7e3e580064b.jpg: 640x640 1 Reading, 9.5ms\n",
      "image 162/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame137_png.rf.63107347371d18af3084d3da3c482853.jpg: 640x640 1 Reading, 11.1ms\n",
      "image 163/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame173_png.rf.14f2feabf59ecf243fe61a76d50212d1.jpg: 640x640 1 Reading, 10.0ms\n",
      "image 164/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame179_png.rf.7f00ac8180ddb000b6d8aa2dd5be5352.jpg: 640x640 1 Reading, 9.6ms\n",
      "image 165/226 d:\\research2\\classroom-attention\\data\\test\\images\\read04_rgb_4_frame192_png.rf.e1c614ecde24b1999a5c91d892c5b181.jpg: 640x640 1 Reading, 9.6ms\n",
      "image 166/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame76_png.rf.55ac3124331cff8923984a7f874f575e.jpg: 640x640 1 Reading, 10.4ms\n",
      "image 167/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame79_png.rf.b3fb2a2379b7c6a996738dfcb442711c.jpg: 640x640 1 Reading, 8.9ms\n",
      "image 168/226 d:\\research2\\classroom-attention\\data\\test\\images\\read07_rgb_2_frame83_png.rf.4d2853e5659337c00525bcacef1d1d1f.jpg: 640x640 1 Reading, 10.2ms\n",
      "image 169/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame19_png.rf.d85b5e665ceafc964b581452fabb989e.jpg: 640x640 1 Reading, 11.3ms\n",
      "image 170/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame239_png.rf.836feeacfb43e83b96e31a6c1f7095d9.jpg: 640x640 1 Reading, 14.7ms\n",
      "image 171/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame28_png.rf.4d8bb6f2dcec05fc9b7f9730d995e069.jpg: 640x640 1 Reading, 10.3ms\n",
      "image 172/226 d:\\research2\\classroom-attention\\data\\test\\images\\read10_rgb_1_frame29_png.rf.280e2dfce72dd4b34eef4bb686fd663b.jpg: 640x640 1 Reading, 9.7ms\n",
      "image 173/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame10_png.rf.8a5e3f231a8c12083cce3b6d8a8a7047.jpg: 640x640 1 Reading, 8.2ms\n",
      "image 174/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame26_png.rf.2a84662f0b45f2b9e8834ab65b81e361.jpg: 640x640 1 Reading, 9.8ms\n",
      "image 175/226 d:\\research2\\classroom-attention\\data\\test\\images\\read11_rgb_1_frame27_png.rf.96e04fb3b3cae36ae3268e7946f38338.jpg: 640x640 1 Reading, 8.4ms\n",
      "image 176/226 d:\\research2\\classroom-attention\\data\\test\\images\\read13_rgb_3_frame204_png.rf.f0b6db3ba56942d451e99df0e014c7c3.jpg: 640x640 1 Reading, 8.1ms\n",
      "image 177/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_1_frame22_png.rf.01ec55b73b0bb9d3edb6285cb15fdf50.jpg: 640x640 1 Reading, 8.9ms\n",
      "image 178/226 d:\\research2\\classroom-attention\\data\\test\\images\\read16_rgb_4_frame3_png.rf.8bc93b6d3699e91bfd3e6899fdd85a4d.jpg: 640x640 1 Reading, 9.8ms\n",
      "image 179/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame117_png.rf.1f6cbfa8432f1638e543fcfd591ebee9.jpg: 640x640 1 Reading, 8.7ms\n",
      "image 180/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_2_frame119_png.rf.3662f8ba4bb01b5cf6b5cc7495b24d9b.jpg: 640x640 1 Reading, 8.7ms\n",
      "image 181/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame131_png.rf.34540fcf480ee68f8a612f8489523e11.jpg: 640x640 1 Reading, 9.3ms\n",
      "image 182/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame133_png.rf.127bdfc99254fe09060d247a27779fff.jpg: 640x640 1 Reading, 8.0ms\n",
      "image 183/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame143_png.rf.80bced075da7b2d5e7be3b0940d913b7.jpg: 640x640 1 Reading, 8.7ms\n",
      "image 184/226 d:\\research2\\classroom-attention\\data\\test\\images\\read17_rgb_3_frame242_png.rf.45e6abe238e2e66d088ddc00ffb8d366.jpg: 640x640 1 Reading, 9.0ms\n",
      "image 185/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame120_png.rf.4ff9286dee9cf53cf26a82ba8f170dd1.jpg: 640x640 1 Reading, 9.1ms\n",
      "image 186/226 d:\\research2\\classroom-attention\\data\\test\\images\\read25_rgb_2_frame57_png.rf.5ae953d3456e283a6965299d50161fc0.jpg: 640x640 1 Reading, 8.8ms\n",
      "image 187/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame225_png.rf.6a3c71cc2b11a9e9a04eba75221e71f8.jpg: 640x640 1 Reading, 8.7ms\n",
      "image 188/226 d:\\research2\\classroom-attention\\data\\test\\images\\read30_rgb_2_frame240_png.rf.e1a259e9c07e63e97f17927276770534.jpg: 640x640 1 Reading, 8.2ms\n",
      "image 189/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame10_png.rf.baa790d16c1be891a3e4d07abdaeacfd.jpg: 640x640 1 Reading, 9.2ms\n",
      "image 190/226 d:\\research2\\classroom-attention\\data\\test\\images\\read32_rgb_2_frame23_png.rf.a670b0b861cd69a80f56f31859727d1b.jpg: 640x640 1 Reading, 8.9ms\n",
      "image 191/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame14_png.rf.90a1b46716b4787d6ac73d8bbecf9367.jpg: 640x640 1 Reading, 9.5ms\n",
      "image 192/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame16_png.rf.60dbd8cba506f1bac0348c3100ce34b6.jpg: 640x640 1 Reading, 8.3ms\n",
      "image 193/226 d:\\research2\\classroom-attention\\data\\test\\images\\read_01_rgb_1_frame26_png.rf.1bfe47aa92e0283f40ef62def13d74af.jpg: 640x640 1 Reading, 9.3ms\n",
      "image 194/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame350_png.rf.d3db8b8e8d96681456460d2c7d721e52.jpg: 640x640 1 Sleeping, 8.2ms\n",
      "image 195/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame365_png.rf.7b955e726b0e21927bee79809867e935.jpg: 640x640 1 Sleeping, 8.5ms\n",
      "image 196/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame367_png.rf.8757710fd35f1cc3c071a70f34acf5d6.jpg: 640x640 1 Sleeping, 8.9ms\n",
      "image 197/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_1_frame381_png.rf.824acbd869aabe62b9c47e1b5e1b6aa8.jpg: 640x640 1 Sleeping, 9.9ms\n",
      "image 198/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame131_png.rf.0b9ff50aca0a9c4e720fd2fc019112a3.jpg: 640x640 1 Sleeping, 8.2ms\n",
      "image 199/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep01_rgb_3_frame132_png.rf.ae98929a07f07ca51e650b8c4330565b.jpg: 640x640 1 Sleeping, 9.1ms\n",
      "image 200/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep02_rgb_3_frame208_png.rf.8e5cea278e41d658979dc697bb4ee698.jpg: 640x640 1 Sleeping, 8.9ms\n",
      "image 201/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame10_png.rf.75992b953dacacc68a5d5a167c987f8a.jpg: 640x640 1 Sleeping, 8.5ms\n",
      "image 202/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_1_frame6_png.rf.77fce1c8dc9c8ed7d78e6cda97f344e2.jpg: 640x640 1 Sleeping, 9.2ms\n",
      "image 203/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep04_rgb_4_frame53_png.rf.03cea74d0449c98903ddf2f18bd0a76d.jpg: 640x640 1 Sleeping, 8.6ms\n",
      "image 204/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_1_frame7_png.rf.42c1ea116a511ab7f4cd9967858bdd63.jpg: 640x640 1 Sleeping, 8.7ms\n",
      "image 205/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep05_rgb_3_frame2_png.rf.713fa271516429ffd48b702c4ec394f4.jpg: 640x640 1 Sleeping, 9.8ms\n",
      "image 206/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame491_png.rf.8d23c808b52aa0ba76114c8514438ad3.jpg: 640x640 1 Sleeping, 7.7ms\n",
      "image 207/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep07_rgb_1_frame499_png.rf.4a25a4b0a4738abb1b5f098d1d13a81f.jpg: 640x640 1 Sleeping, 9.0ms\n",
      "image 208/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame12_png.rf.00e6a56fc283463d91c5207b8e2abfea.jpg: 640x640 1 Sleeping, 8.4ms\n",
      "image 209/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame1_png.rf.fc729f7d8dab490d64600f2716c29eca.jpg: 640x640 1 Sleeping, 8.8ms\n",
      "image 210/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep12_rgb_1_frame5_png.rf.839270aea831b7bf95e401d3f921dca7.jpg: 640x640 1 Sleeping, 8.1ms\n",
      "image 211/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame14_png.rf.88fce954118467b425233cba75ed4d5e.jpg: 640x640 1 Sleeping, 10.1ms\n",
      "image 212/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame22_png.rf.e2680f4df744b654a8f8ad25898a96dc.jpg: 640x640 1 Sleeping, 8.4ms\n",
      "image 213/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_1_frame5_png.rf.03889e765cb346db5a9b11b4fa568011.jpg: 640x640 1 Sleeping, 9.1ms\n",
      "image 214/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep18_rgb_3_frame457_png.rf.38355f92db1797dcffdc4ad1ee85cc03.jpg: 640x640 1 Sleeping, 8.8ms\n",
      "image 215/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame16_png.rf.6512c41305f79fd3621ee84ac52beace.jpg: 640x640 1 Sleeping, 8.6ms\n",
      "image 216/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep19_rgb_1_frame5_png.rf.7211aaba76cc164190fcc0ece61f378c.jpg: 640x640 1 Sleeping, 9.4ms\n",
      "image 217/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep20_rgb_1_frame197_png.rf.56fbbc05973390d04699eef597b957b5.jpg: 640x640 1 Sleeping, 9.6ms\n",
      "image 218/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame295_png.rf.f4d3b3ca8ac0b3f1c72a884ae96c98f2.jpg: 640x640 1 Sleeping, 8.2ms\n",
      "image 219/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep21_rgb_3_frame306_png.rf.061aba5baac216e1d24330e7fbd51445.jpg: 640x640 1 Sleeping, 9.0ms\n",
      "image 220/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep25_rgb_1_frame3_png.rf.486a414ebb1ea6c8ac4ce613062a2447.jpg: 640x640 1 Sleeping, 8.1ms\n",
      "image 221/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame219_png.rf.a53caaf46f636872db9f6c96094dc345.jpg: 640x640 1 Sleeping, 9.9ms\n",
      "image 222/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep29_rgb_1_frame228_png.rf.9378688b6e21c581cd53d9c6dcdba410.jpg: 640x640 1 Sleeping, 9.0ms\n",
      "image 223/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame4_png.rf.867510b6586afde44bf821ac546d5e5e.jpg: 640x640 1 Sleeping, 9.5ms\n",
      "image 224/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep30_rgb_1_frame9_png.rf.5e8bff960fb897acc90df0fc49223c03.jpg: 640x640 1 Sleeping, 8.8ms\n",
      "image 225/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame13_png.rf.c313e943c01dc74cac17c3926236bc38.jpg: 640x640 1 Sleeping, 9.4ms\n",
      "image 226/226 d:\\research2\\classroom-attention\\data\\test\\images\\sleep31_rgb_1_frame4_png.rf.7f6a45dd314f42787b1a5d045c0e0cd1.jpg: 640x640 1 Sleeping, 8.5ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov11m\\prediction_outputs\\yolov11m-pred\u001b[0m\n",
      "226 labels saved to yolov11m\\prediction_outputs\\yolov11m-pred\\labels\n",
      "\n",
      " Sample predictions saved in yolov11m\\prediction_outputs\\yolov11m-pred\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = 'models/yolo11m.pt'\n",
    "DATASET_YAML = 'data/data.yaml'\n",
    "\n",
    "TRAIN_PARAMS = {\n",
    "    'data': DATASET_YAML,\n",
    "    'epochs': 100,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'name': 'classroom_attention_yolov11m',\n",
    "    'project': 'yolov11m/train',\n",
    "    'workers': 4,\n",
    "    'optimizer': 'SGD',\n",
    "    'patience': 20,\n",
    "    'device': '0',\n",
    "    'save': True,\n",
    "    'exist_ok': True,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "def train_model(model_path, params):\n",
    "    print(f\"\\n Loading Model: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    print(\"Resolved model name:\", model.model_name)\n",
    "    \n",
    "    print(\"\\n Training Started...\\n\")\n",
    "    results = model.train(**params)\n",
    "    \n",
    "    print(\"\\n Training Complete!\")\n",
    "    return model, results\n",
    "\n",
    "def evaluate_model(model, dataset_yaml):\n",
    "    print(\"\\n Running validation on VALIDATION split...\\n\")\n",
    "    val_metrics = model.val(data=dataset_yaml, split='val')\n",
    "\n",
    "    print(\"\\n Validation Metrics:\")\n",
    "    print(f\"mAP50: {val_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {val_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {val_metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {val_metrics.box.mr:.4f}\")\n",
    "    plot_per_class_metrics(\n",
    "    val_metrics.box.p,\n",
    "    val_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov11m/evaluation_plots/validation/per_val_class_metrics.png'\n",
    ")\n",
    "    print(\"\\n Running validation on TEST split...\\n\")\n",
    "    test_metrics = model.val(data=dataset_yaml, split='test')\n",
    "\n",
    "    print(\"\\n Test Metrics:\")\n",
    "    print(f\"mAP50: {test_metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {test_metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {test_metrics.box.mp}\")\n",
    "    print(f\"Recall: {test_metrics.box.mr}\")\n",
    "    plot_per_class_metrics(\n",
    "    test_metrics.box.p,\n",
    "    test_metrics.box.r,\n",
    "    class_names=['Looking_Forward', 'Raising_Hand', 'Reading', 'Sleeping', 'Turning_Around'],\n",
    "    save_path='yolov11m/evaluation_plots/validation/per_test_class_metrics.png'\n",
    ")\n",
    "    return val_metrics, test_metrics\n",
    "\n",
    "\n",
    "def plot_metrics(metrics, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        map50 = metrics.box.map50\n",
    "        map95 = metrics.box.map\n",
    "        precision = metrics.box.mp\n",
    "        recall = metrics.box.mr\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(['mAP@50', 'mAP@50-95', 'Precision', 'Recall'],\n",
    "                [map50, map95, precision, recall],\n",
    "                color=['dodgerblue', 'teal', 'orange', 'tomato'])\n",
    "\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('Overall Detection Metrics')\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(save_dir, 'overall_metrics.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\" Metric plot saved to {plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error while plotting metrics: {e}\")\n",
    "\n",
    "\n",
    "def plot_training_loss_curves(run_dir='yolov11m/detect/exp', save_dir='yolov11m/training_plots'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results_path = os.path.join(run_dir, 'results.csv')\n",
    "    if not os.path.isfile(results_path):\n",
    "        print(f\" No results.csv found at {results_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "\n",
    "    # Plot available loss curves — check column names if needed\n",
    "    loss_keys = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plotted = False\n",
    "    for key in loss_keys:\n",
    "        if key in df.columns:\n",
    "            plt.plot(df.index, df[key], label=key)\n",
    "            plotted = True\n",
    "\n",
    "    if plotted:\n",
    "        plt.title(\"Training Loss Curves\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plot_path = os.path.join(save_dir, 'loss_curves.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\" Training curves saved to {plot_path}\")\n",
    "    else:\n",
    "        print(\" No loss columns found in results.csv\")\n",
    "\n",
    "\n",
    "def plot_predictions(model, save_dir='yolov11m/prediction_outputs'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    results = model.predict(\n",
    "        source=\"data/test/images\",\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        conf=0.25,\n",
    "        max_det=100,\n",
    "        project='yolov11m/prediction_outputs',\n",
    "        name='yolov11m-pred'\n",
    "    )\n",
    "    print(f\"\\n Sample predictions saved in {results[0].save_dir}\")\n",
    "\n",
    "def plot_per_class_metrics(precision, recall, class_names=None, save_path=None):\n",
    "    num_classes = len(precision)\n",
    "    indices = np.arange(num_classes)\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    width = 0.35  # Width of bars\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(indices - width/2, precision, width, label='Precision', color='skyblue')\n",
    "    plt.bar(indices + width/2, recall, width, label='Recall', color='salmon')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Per-Class Precision and Recall')\n",
    "    plt.xticks(indices, class_names, rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "model, train_results = train_model(MODEL_NAME, TRAIN_PARAMS)\n",
    "\n",
    "plot_training_loss_curves(run_dir='yolov11m/train/classroom_attention_yolov11m')\n",
    "\n",
    "val_metrics, test_metrics = evaluate_model(model, DATASET_YAML)\n",
    "plot_metrics(val_metrics, save_dir='yolov11m/evaluation_plots/validation')\n",
    "plot_metrics(test_metrics, save_dir='yolov11m/evaluation_plots/test')\n",
    "plot_predictions(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
